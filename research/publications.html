---
layout: page
title: "Publications"
description: ""
tagline: "last updated on November 02, 2015"
group: research
---
{% include JB/setup %}
<ul class="nav nav-tabs">
<li><a href="#All" data-toggle="tab">All (57)</a></li>
<li><a href="#Journalarticles" data-toggle="tab">Journal articles (7)</a></li>
<li><a href="#Bookchapters" data-toggle="tab">Book chapters (4)</a></li>
<li><a href="#Conferenceandworkshopproceedings" data-toggle="tab">Conference and workshop proceedings (45)</a></li>
</ul>
<div id="myTabContent" class="tab-content">
<div class="tab-pane fade in active" id="All">
<div class="accordion" id="accordionAll">
<h3>2015</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseCharlet2015_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Charlet2015']);">
        What Makes a Speaker Recognizable in TV Broadcast? Going Beyond Speaker Identification Error Rate
        </a>
    </div>
    <div id="collapseCharlet2015_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Delphine Charlet, Johann Poignant, Hervé Bredin, Corinne Fredouille, Sylvain Meignier
<p><em>ERRARE 2015, Second Workshop on Errors By Humans and Machines in Multimedia, Multimodal, and Multilingual Data Processing</em></p>
<blockquote><p>Speaker identification approaches for TV broadcast are usually evaluated and compared based on global error rates derived from the overall duration of missed detection, false alarm and confusion. Based on the analysis of the output of the systems submitted to the final round of the French evaluation campaign REPERE, this paper highlights the fact that these average metrics lead to the incorrect intuition that current state-of-the-art algorithms partially recognize all speakers. Setting aside incorrect diarization and adverse acoustic conditions, we show that their performance is in fact essentially bi-modal: in a given show, either all speech turns of a speaker are correctly identified or none of them are. We then proceed with trying to understand and explain this behavior, through perfomance prediction experiments. These experiments show that the most discriminant speaker characteristics are -- first -- their total speech duration in the current show and -- then only -- the amount of training data available to build their acoustic model.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Charlet2015']);">.bib</a> [Charlet2015] | <i class="icon-book"></i> <a href="/download/pdfs/Charlet2015.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Charlet2015']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseKnyazeva2015_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Knyazeva2015']);">
        Structured Prediction for Speaker Identification in TV Series
        </a>
    </div>
    <div id="collapseKnyazeva2015_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Elena Knyazeva, Guillaume Wisniewski, Hervé Bredin, Fran\ccois Yvon
<p><em>Interspeech 2015, 16th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>Though radio and TV broadcast are highly structured documents, state-of-the-art speaker identification algorithms do not take advantage of this information to improve prediction performance: speech turns are usually identified independently from each other, using unstructured multi-class classification approaches. In this work, we propose to address speaker identification as a sequence labeling task and use two structured prediction techniques to account for the inherent temporal structure of interactions between speakers: the first one relies on Conditional Random Field and can take into account local relations between two consecutive speech turns; the second one, based on the SEARN framework, sacrifices exact inference for the sake of the expressiveness of the model and is able to incorporate rich structure information during prediction. Experiments performed on The Big Bang Theory TV series show that structured prediction techniques outperform the  standard unstructured approach.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Knyazeva2015']);">.bib</a> [Knyazeva2015] | <i class="icon-book"></i> <a href="/download/pdfs/Knyazeva2015.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Knyazeva2015']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBudnik2015_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Budnik2015']);">
        Collaborative Annotation for Person Identification in TV Shows
        </a>
    </div>
    <div id="collapseBudnik2015_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<p><em>Interspeech 2015, 16th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>This paper presents a collaborative annotation framework for person identification in TV shows. The web annotation front-end will be demonstrated during the Show and Tell session. All the code for annotation is made available on github. The tool can also be used in a crowd-sourcing environment.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Budnik2015']);">.bib</a> [Budnik2015] | <i class="icon-book"></i> <a href="/download/pdfs/Budnik2015.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Budnik2015']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsePoignant2015_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Poignant2015']);">
        Multimodal Person Discovery in Broadcast TV at MediaEval 2015
        </a>
    </div>
    <div id="collapsePoignant2015_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Johann Poignant, Hervé Bredin, Claude Barras
<p><em>MediaEval 2015</em></p>
<blockquote><p>We describe the ``Multimodal Person Discovery in Broadcast TV'' task of MediaEval 2015 benchmarking initiative. Participants are asked to return the names of people who can be both seen as well as heard in every shot of a collection of videos. The list of people is not known a priori and their names must be discovered in an unsupervised way from media content using text overlay or speech transcripts. The task is evaluated using information retrieval metrics, based on a posteriori collaborative annotation of the test corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Poignant2015']);">.bib</a> [Poignant2015] | <i class="icon-book"></i> <a href="/download/pdfs/Poignant2015.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Poignant2015']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsePoignant2015a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Poignant2015a']);">
        LIMSI @ MediaEval 2015: Person Discovery in Broadcast TV Task
        </a>
    </div>
    <div id="collapsePoignant2015a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Johann Poignant, Hervé Bredin, Claude Barras
<p><em>MediaEval 2015</em></p>
<blockquote><p>This paper describes the algorithm tested by the LIMSI team in the MediaEval 2015 Person Discovery in Broadcast TV Task. For this task we used an audio/video diarization process constrained by names written on screen. These names are used to both identify clusters and prevent the fusion of two clusters with different co-occurring names. This method obtained 83.1% of EwMAP tuned on the out-domain development corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Poignant2015a']);">.bib</a> [Poignant2015a] | <i class="icon-book"></i> <a href="/download/pdfs/Poignant2015a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Poignant2015a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBruneau2015_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bruneau2015']);">
        A Visual Analytics Approach to Finding Factors Improving Automatic Speaker Identification
        </a>
    </div>
    <div id="collapseBruneau2015_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Pierrick Bruneau, Mickaël Stefas, Hervé Bredin, Johann Poignant, Thomas Tamisier, Claude Barras
<p><em>ICMI 2015, 17th International Conference on Multimodal Interaction</em></p>
<blockquote><p>Classification quality criteria such as precision, recall, and F-measure are generally the basis for evaluating contributions in automatic speaker recognition. Specifically, comparisons are carried out mostly via mean values estimated on a set of media. Whilst this approach is relevant to assess improvement w.r.t. the state-of-the-art, or ranking participants in the context of an automatic annotation challenge, it gives little insight to system designers in terms of cues for improving algorithms, hypothesis formulation, and evidence display. This paper presents a design study of a visual and interactive approach to analyze errors made by automatic annotation algorithms. A timeline-based tool emerged from prior steps of this study. A critical review, driven by user interviews, exposes caveats and refines user objectives. The next step of the study is then initiated by sketching designs combining elements of the current prototype to principles newly identified as relevant.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bruneau2015']);">.bib</a> [Bruneau2015] | <i class="icon-book"></i> <a href="/download/pdfs/Bruneau2015.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bruneau2015']);">.pdf</a>        </div>
    </div>
</div>
<h3>2014</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseRoy2014_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Roy2014']);">
        Lexical Speaker Identification in TV Shows
        </a>
    </div>
    <div id="collapseRoy2014_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Anindya Roy, Hervé Bredin, William Hartmann, Viet-Bac Le, Claude Barras, Jean-Luc Gauvain
<p><em>Multimedia Tools and Applications</em></p>
<blockquote><p>It is possible to use lexical information extracted from speech transcripts for speaker identification (SID), either on its own or to improve the performance of standard cepstral-based SID systems upon fusion. This was established before typically using isolated speech from single speakers (NIST SRE corpora, parliamentary speeches). On the contrary, this work applies lexical approaches for SID on a different type of data. It uses the REPERE corpus consisting of unsegmented multiparty conversations, mostly debates, discussions and Q&A sessions from TV shows. It is hypothesized that people give out clues to their identity when speaking in such settings which this work aims to exploit. The impact on SID performance of the diarization front-end required to pre-process the unsegmented data is also measured. Four lexical SID approaches are studied in this work, including TFIDF, BM25 and LDA-based topic modeling. Results are analysed in terms of TV shows and speaker roles. Lexical approaches achieve low error rates for certain speaker roles such as anchors and journalists, sometimes lower than a standard cepstral-based Gaussian Supervector -- Support Vector Machine (GSV-SVM) system. Also, in certain cases, the lexical system shows modest improvement over the cepstral-based system performance using score-level sum fusion. To highlight the potential of using lexical information not just to improve upon cepstral-based SID systems but as an independent approach in its own right, initial studies on crossmedia SID is briefly reported. Instead of using speech data as all cepstral systems require, this approach uses Wikipedia texts to train lexical speaker models which are then tested on speech transcripts to identify speakers.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Roy2014']);">.bib</a> [Roy2014] | <i class="icon-book"></i> <a href="/download/pdfs/Roy2014.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Roy2014']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2014_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2014']);">
        Person Instance Graphs for Mono-, Cross- and Multi-Modal Person Recognition in Multimedia Data. Application to Speaker Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseBredin2014_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Anindya Roy, Viet-Bac Le, Claude Barras
<p><em>International Journal of Multimedia Information Retrieval</em></p>
<blockquote><p>This work introduces a unified framework for mono-, cross- and multi-modal person recognition in multimedia data. Dubbed Person Instance Graph, it models the person recognition task as a graph mining problem: i.e. finding the best mapping between person instance vertices and identity vertices. Practically, we describe how the approach can be applied to speaker identification in TV broadcast. Then, a solution to the above-mentioned mapping problem is proposed. It relies on Integer Linear Programming to model the problem of clustering person instances based on their identity. We provide an in-depth theoretical definition of the optimization problem. Moreover, we improve two fundamental aspects of our previous related work: the problem constraints and the optimized objective function. Finally, a thorough experimental evaluation of the proposed framework is performed on a publicly available benchmark database. Depending on the graph configuration (i.e. the choice of its vertices and edges), we show that multiple tasks can be addressed interchangeably (e.g. speaker diarization, supervised or unsupervised speaker identification), significantly outperforming state-of-the-art mono-modal approaches.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2014']);">.bib</a> [Bredin2014] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2014.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2014']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseRoy2014a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Roy2014a']);">
        TVD: a Reproducible and Multiply Aligned TV Series Dataset
        </a>
    </div>
    <div id="collapseRoy2014a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Anindya Roy, Camille Guinaudeau, Hervé Bredin, Claude Barras
<p><em>LREC 2014, 9th Language Resources and Evaluation Conference</em></p>
<blockquote><p>We present a new dataset built around two TV series, The Big Bang Theory (a situation comedy) and Game of Thrones (a fantasy drama). It has multiple tracks including dialogue, crowd-sourced textual descriptions and metadata, all time-stamped and temporally aligned with each other. We provide tools to reproduce it for research purposes, provided that one has legally acquired the DVDs of the series. The alignment algorithm used is evaluated on a manually aligned subset of the data.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Roy2014a']);">.bib</a> [Roy2014a] | <i class="icon-book"></i> <a href="/download/pdfs/Roy2014a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Roy2014a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2014a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2014a']);">
        Person Instance Graphs for Named Speaker Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseBredin2014a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Antoine Laurent, Achintya Sarkar, Viet-Bac Le, Sophie Rosset, Claude Barras
<p><em>Odyssey 2014, The Speaker and Language Recognition Workshop</em></p>
<blockquote><p>We address the problem of named speaker identification in TV broadcast which consists in answering the question ''who speaks when?'' with the real identity of speakers, using person names automatically obtained from speech transcripts. While existing approaches rely on a first speaker diarization step followed by a local name propagation step to speaker clusters, we propose a unified framework called person instance graph where both steps are jointly modeled as a global optimization problem, then solved using integer linear programming. Moreover, when available, acoustic speaker models can be added seamlessly to the graph structure for joint named and acoustic speaker identification - leading to a 10% error decrease (from 45% down to 35%) over a state-of-the-art i-vector speaker identification system on the REPERE TV broadcast corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2014a']);">.bib</a> [Bredin2014a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2014a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2014a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseStrat2014_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Strat2014']);">
        Hierarchical Late Fusion for Concept Detection in Videos
        </a>
    </div>
    <div id="collapseStrat2014_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Sabin Tiberius Strat, Alexandre Benoit, Patrick Lambert, Hervé Bredin, Georges Quénot
<p><em>Fusion in Computer Vision -- Understanding Complex Visual Content</em></p>
<blockquote><p>Current research shows that the detection of semantic concepts (animal, bus, person, dancing etc.) in multimedia documents such as videos, requires the use of several types of complementary descriptors in order to achieve good results. In this work, we explore strategies for combining dozens of complementary content descriptors (or ``experts'') in an efficient way, through the use of late fusion approaches, for concept detection in multimedia documents. We explore two fusion approaches that share a common structure: both start with a clustering of experts stage, continue with an intra-cluster fusion and finish with an inter-cluster fusion, and we also experiment with other state-of-the-art methods. The first fusion approach relies on a priori knowledge about the internals of each expert to group the set of available experts by similarity. The second approach automatically obtains measures on the similarity of experts from their output to group the experts using agglomerative clustering, and then combines the results of this fusion with those from other methods. In the end, we show that an additional performance boost can be obtained by also considering the context of multimedia elements.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Strat2014']);">.bib</a> [Strat2014] | <i class="icon-book"></i> <a href="/download/pdfs/Strat2014.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Strat2014']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBruneau2014_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bruneau2014']);">
        A Web-based Tool for the Visual Analysis of Media Annotations
        </a>
    </div>
    <div id="collapseBruneau2014_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Pierrick Bruneau, Mickaël Stefas, Hervé Bredin, Anh-Phuong Ta, Thomas Tamisier, Claude Barras
<p><em>iV 2014, 18th International Conference Information Visualisation</em></p>
<blockquote><p>Multimedia annotation algorithms infer localized meta-data in multimedia content, e.g. speakers or appearing faces. There is a growing need of experts from this domain to perform advanced analyses, that go beyond medium-scale quality metrics. This paper describes a novel visual tool, that applies interactive visualization principles to the multimedia expert concerns. Multiple coordinated views, augmented by interactive inspection facilities, ease the navigation in media annotations, and the visual detection of relevant information. The effectiveness of the proposition is demonstrated by experimental scenarios on a real multimedia corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bruneau2014']);">.bib</a> [Bruneau2014] | <i class="icon-book"></i> <a href="/download/pdfs/Bruneau2014.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bruneau2014']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBruneau2014a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bruneau2014a']);">
        Collaborative Annotation of Multimedia Resources
        </a>
    </div>
    <div id="collapseBruneau2014a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Pierrick Bruneau, Mickaël Stefas, Mateusz Budnik, Johann Poignant, Hervé Bredin, Thomas Tamisier, Beno\^it Otjacques
<p><em>CDVE 2014, 11th International Conference on Cooperative Design, Visualization and Engineering</em></p>
<blockquote><p>Reference multimedia corpora for use in automated annotation algorithms are very demanding of manual work. The Camomile project advocates the joint progress of automated annotation methods and tools for improving the benchmark resources. This paper shows some work in progress in interactive visualization of annotations, and perspectives in harnessing the collaboration between manual annotators, algorithm designers, and benchmark administrators.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bruneau2014a']);">.bib</a> [Bruneau2014a] | <i class="icon-book"></i> <a href="/download/pdfs/Bruneau2014a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bruneau2014a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseGuinaudeau2014_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Guinaudeau2014']);">
        LIMSI @ MediaEval SED 2014
        </a>
    </div>
    <div id="collapseGuinaudeau2014_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Camille Guinaudeau, Antoine Laurent, Hervé Bredin
<p><em>MediaEval 2014</em></p>
<blockquote><p>This paper provides an overview of the Social Event Detection (SED) system developed at LIMSI for the 2014 campaign. Our approach is based on a hierarchical agglomerative clustering that uses textual metadata, user-based knowledge and geographical information. These different sources of knowledge, either used separately or in cascade, reach good results for the full clustering subtask with a normalized mutual information equal to 0.95 and F1 scores greater than 0.82 for our best run.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Guinaudeau2014']);">.bib</a> [Guinaudeau2014] | <i class="icon-book"></i> <a href="/download/pdfs/Guinaudeau2014.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Guinaudeau2014']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2014b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2014b']);">
        "Sheldon speaking, bonjour!": Leveraging Multilingual Tracks for (Weakly) Supervised Speaker Identification
        </a>
    </div>
    <div id="collapseBredin2014b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Anindya Roy, Nicolas Pécheux, Alexandre Allauzen
<p><em>ACM MM 2014, 22nd ACM International Conference on Multimedia</em></p>
<blockquote><p>We address the problem of speaker identification in multimedia data, and TV series in particular. While speaker identification is traditionally a supervised machine-learning task, our first contribution is to significantly reduce the need for costly preliminary manual annotations through the use of automatically aligned (and potentially noisy) fan-generated transcripts and subtitles. We show that both speech activity detection and speech turn identification modules trained in this weakly supervised manner achieve similar performance as their fully supervised counterparts (i.e. relying on fine manual speech/non-speech/speaker annotation). Our second contribution relates to the use of multilingual audio tracks usually available with this kind of content to significantly improve the overall speaker identification performance. Reproducible experiments (including dataset, manual annotations and source code) performed on the first six episodes of The Big Bang Theory TV series show that combining the French audio track (containing dubbed actor voices) with the English one (with the original actor voices) improves the overall English speaker identification performance by 5% absolute and up to 70% relative on the five main characters.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2014b']);">.bib</a> [Bredin2014b] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2014b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2014b']);">.pdf</a>        </div>
    </div>
</div>
<h3>2013</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2013_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2013']);">
        Integer Linear Programming for Speaker Diarization and Cross-Modal Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseBredin2013_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Johann Poignant
<p><em>Interspeech 2013, 14th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>Most state-of-the-art approaches address speaker diarization as a hierarchical agglomerative clustering problem in the audio domain. In this paper, we propose to revisit one of them: speech turns clustering based on the Bayesian Information Criterion (a.k.a. BIC clustering). First, we show how to model it as an integer linear programming (ILP) problem.Its resolution leads to the same overall diarization error rate as standard BIC clustering but generates significantly purer speaker clusters. Then, we describe how this approach can easily be extended to the audiovisual domain and TV broadcast in particular. The straightforward integration of detected overlaid names (used to introduce guests or journalists, and obtained via video OCR) into a multimodal ILP problem yields significantly better speaker diarization results. Finally, we explain how this novel paradigm can incidentally be used for unsupervised speaker identification (i.e. not relying on any prior acoustic speaker models). Experiments on the REPERE TV broadcast corpus show that it achieves performance close to that of an oracle capable of identifying any speaker as long as their name appears on screen at least once in the video.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2013']);">.bib</a> [Bredin2013] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2013.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2013']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2013a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2013a']);">
        QCompere @ REPERE 2013
        </a>
    </div>
    <div id="collapseBredin2013a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Johann Poignant, Guillaume Fortier, Makarand Tapaswi, Viet-Bac Le, Anindya Roy, Claude Barras, Sophie Rosset, Achintya Sarkar, Qian Yang, Hua Gao, Alexis Mignon, Jakob Verbeek, Laurent Besacier, Georges Quénot, Hazim Kemal Ekenel, Rainer Stiefelhagen
<p><em>SLAM 2013, First Workshop on Speech, Language and Audio for Multimedia</em></p>
<blockquote><p>We describe QCompere consortium submissions to the REPERE 2013 evaluation campaign. The REPERE challenge aims at gathering four communities (face recognition, speaker identification, optical character recognition and named entity detection) towards the same goal: multimodal person recognition in TV broadcast. First, four mono-modal components are introduced (one for each foregoing community) constituting the elementary building blocks of our various submissions. Then, depending on the target modality (speaker or face recognition) and on the task (supervised or unsupervised recognition), four different fusion techniques are introduced: they can be summarized as propagation-, classifier-, rule- or graph-based approaches. Finally, their performance is evaluated on REPERE 2013 test set and their advantages and limitations are discussed.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2013a']);">.bib</a> [Bredin2013a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2013a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2013a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsePoignant2013_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Poignant2013']);">
        Towards a Better Integration of Written Names for Unsupervised Speakers Identification in Videos
        </a>
    </div>
    <div id="collapsePoignant2013_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Johann Poignant, Hervé Bredin, Laurent Besacier, Georges Quénot, Claude Barras
<p><em>SLAM 2013, First Workshop on Speech, Language and Audio for Multimedia</em></p>
<blockquote><p>Existing methods for unsupervised identification of speakers in TV broadcast usually rely on the output of a speaker diarization module and try to name each cluster using names provided by another source of information: we call it ``late naming''. Hence, written names extracted from title blocks tend to lead to high precision identification, although they cannot correct errors made during the clustering step. In this paper, we extend our previous ``late naming'' approach in two ways: ``integrated naming'' and ``early naming''. While ``late naming'' relies on a speaker diarization module optimized for speaker diarization, ``integrated naming'' jointly optimize speaker diarization and name propagation in terms of identification errors. ``Early naming'' modifies the speaker diarization module by adding constraints preventing two clusters with different written names to be merged together. While ``integrated naming'' yields similar identification performance as ``late naming'' (with better precision), ``early naming'' improves over this baseline both in terms of identification error rate and stability of the clustering stopping criterion.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Poignant2013']);">.bib</a> [Poignant2013] | <i class="icon-book"></i> <a href="/download/pdfs/Poignant2013.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Poignant2013']);">.pdf</a>        </div>
    </div>
</div>
<h3>2012</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseDelezoide2012_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Delezoide2012']);">
        IRIM at TRECVID 2011: Semantic Indexing and Instance Search
        </a>
    </div>
    <div id="collapseDelezoide2012_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Bertrand Delezoide, Frédéric Precioso, Philippe Gosselin, Miriam Redi, Bernard Mérialdo, Lionel Granjon, Denis Pellerin, Michèle Rombaut, Hervé Jégou, Rémi Vieux, Boris Mansencal, Jenny Benois-Pineau, Stéphane Ayache, Bahjat Safadi, Franck Thollard, Georges Quénot, Hervé Bredin, Matthieu Cord, Alexandre Benoit, Patrick Lambert, Tiberius Strat, Joseph Razik, Sébastion Paris, Hervé Glotin
<p><em>TRECVid 2011, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes its participation to the TRECVID 2011 semantic indexing and instance search tasks. For the semantic indexing task, our approach uses a six-stages processing pipelines for computing scores for the likelihood of a video shot to contain a target concept. These scores are then used for producing a ranked list of images or shots that are the most likely to contain the target concept. The pipeline is composed of the following steps: descriptor extraction, descriptor optimization, classification, fusion of descriptor variants, higher-level fusion, and re-ranking. We evaluated a number of different descriptors and tried different fusion strategies. The best IRIM run has a Mean Inferred Average Precision of 0.1387, which ranked us 5th out of 19 participants. For the instance search task, we we used both object based query and frame based query. We formulated the query in standard way as comparison of visual signatures either of object with parts of DB frames or as a comparison of visual signatures of query and DB frames. To produce visual signatures we also used two apporaches: the first one is the baseline Bag-Of-Visual-Words (BOVW) model based on SURF interest point descriptor; the second approach is a Bag-Of-Regions (BOR) model that extends the traditional notion of BOVW vocabulary not only to keypoint-based descriptors but to region based descriptors.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Delezoide2012']);">.bib</a> [Delezoide2012] | <i class="icon-book"></i> <a href="/download/pdfs/Delezoide2012.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Delezoide2012']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2012_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2012']);">
        Segmentation of TV Shows into Scenes using Speaker Diarization and Speech Recognition
        </a>
    </div>
    <div id="collapseBredin2012_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<blockquote><p>We investigate the use of speaker diarization (SD) and automatic speech recognition (ASR) for the segmentation of audiovisual documents into scenes. We introduce multiple monomodal and multimodal approaches based on a state-of-the-art algorithm called generalized scene transition graph (GSTG). First, we extend the latter with the use of semantic information derived from both SD and ASR. Then, multimodal fusion of color histograms, SD and ASR is investigated at various point of the GSTG pipeline (early, late or intermediate fusion). Experiments driven on a few episodes of a popular TV show indicate that SD and ASR can be successfully combined with visual information and bring an additional +11% relative increase in terms of F-Measure for scene boundary detection over the state-of-the-art baseline.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2012']);">.bib</a> [Bredin2012] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2012.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2012']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2012a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2012a']);">
        Community-driven Hierarchical Fusion of Numerous Classifiers: Application to Video Semantic Indexing
        </a>
    </div>
    <div id="collapseBredin2012a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<blockquote><p>We deal with the issue of combining dozens of classifiers into a better one. Our first contribution is the introduction of the notion of communities of classifiers. We build a complete graph with one node per classifier and edges weighted by a measure of similarity between connected classifiers. The resulting community structure is uncovered from this graph using the state-of-the-art Louvain algorithm. Our second contribution is a hierarchical fusion approach driven by these communities. First, intra-community fusion results in one classifier per community. Then, inter-community fusion takes advantage of their complementarity to achieve much better classification performance. Application to the combination of 90 classifiers in the framework of TRECVid 2010 Semantic Indexing task shows a 30% increase in performance relative to a baseline flat fusion.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2012a']);">.bib</a> [Bredin2012a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2012a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2012a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseErcolessi2012_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ercolessi2012']);">
        Toward Plot De-Interlacing in TV Series using Scenes Clustering
        </a>
    </div>
    <div id="collapseErcolessi2012_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Hervé Bredin
<p><em>CBMI 2012, 10th Workshop on Content-Based Multimedia Indexing</em></p>
<blockquote><p>Multiple sub-stories usually coexist in every episode of a TV series. We propose several variants of an approach for plot de-interlacing based on scenes clustering -- with the ultimate goal of providing the end-user with tools for fast and easy overview of one episode, one season or the whole TV series. Each scene can be described in three different ways (based on color histograms, speaker diarization or automatic speech recognition outputs) and four clustering approaches are investigated, one of them based on a graphical representation of the video. Experiments are performed on two TV series of different lengths and formats. We show that semantic descriptors (such as speaker diarization) give the best results and underline that our approach provides useful information for plot de-interlacing.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ercolessi2012']);">.bib</a> [Ercolessi2012] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ercolessi2012']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsePoignant2012_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Poignant2012']);">
        Unsupervised Speaker Identification using Overlaid Texts in TV Broadcast
        </a>
    </div>
    <div id="collapsePoignant2012_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Johann Poignant, Hervé Bredin, Viet-Bac Le, Laurent Besacier, Claude Barras, Georges Quénot
<p><em>Interspeech 2012, 13th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>We propose an approach for unsupervised speaker identification in TV broadcast videos, by combining acoustic speaker diarization with person names obtained via video OCR from overlaid texts. Three methods for the propagation of the overlaid names to the speech turns are compared, taking into account the co-occurence duration between the speaker clusters and the names provided by the video OCR and using a task-adapted variant of the TF-IDF information retrieval coefficient. These methods were tested on the REPERE dry-run evaluation corpus, containing 3 hours of annotated videos. Our best unsupervised system reaches a F-measure of 70.2\% when considering all the speakers, and 81.7\% if anchor speakers are left out. By comparison, a mono-modal, supervised speaker identification system with 535 speaker models trained on matching development data and additional TV and radio data only provided a 57.5\% F-measure when considering all the speakers and 45.7\% without anchor.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Poignant2012']);">.bib</a> [Poignant2012] | <i class="icon-book"></i> <a href="/download/pdfs/Poignant2012.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Poignant2012']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseErcolessi2012a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ercolessi2012a']);">
        Vers un Résumé Automatique de Séries Télévisées basé sur une Recherche Multimodale d'Histoires
        </a>
    </div>
    <div id="collapseErcolessi2012a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Hervé Bredin, Sandrine Mouysset
<p><em>Document Numérique -- Numéro Spécial ``Résumé Automatique des Documents''</em></p>
<blockquote><p>Modern TV series have complex plots made of several intertwined stories following numerous characters. In this paper, we propose an approach for automatically detecting these stories in order to generate video summaries and we propose a visualization tool to have a quick and easy look at TV series. Based on automatic scene segmentation of each TV series episode (a scene is defined as temporally and spatially continuous and semantically coherent), scenes are clustered into stories, made of (non necessarily adjacent) semantically similar scenes. Visual, audio and text modalities are combined to achieve better scene segmentation and story detection performance. An extraction of salient scenes from stories is performed to create the summary. Experimentations are conducted on two TV series with different formats.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ercolessi2012a']);">.bib</a> [Ercolessi2012a] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ercolessi2012a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2012b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2012b']);">
        Fusion of Speech, Faces and Text for Person Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseBredin2012b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Johann Poignant, Makarand Tapaswi, Guillaume Fortier, Viet Bac Le, Thibault Napoleon, Hua Gao, Claude Barras, Sophie Rosset, Laurent Besacier, Jakob Verbeek, Georges Quénot, Frédéric Jurie, Hazim Kemal Ekenel
<p><em>ECCV 2012, Workshop on Information Fusion in Computer Vision for Concept Recognition</em></p>
<blockquote><p>The REPERE challenge is a project aiming at the evaluation of systems for supervised and unsupervised multimodal recognition of people in TV broadcast. In this paper, we describe, evaluate and discuss QCompere consortium submissions to the 2012 \repere evaluation campaign dry-run. Speaker identification (and face recognition) can be greatly improved when combined with name detection through video optical character recognition. Moreover, we show that unsupervised multimodal person recognition systems can achieve performance nearly as good as supervised monomodal ones (with several hundreds of identity models).</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2012b']);">.bib</a> [Bredin2012b] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2012b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2012b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseStrat2012_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Strat2012']);">
        Hierarchical Late Fusion for Concept Detection in Videos
        </a>
    </div>
    <div id="collapseStrat2012_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Tiberius Strat, Alexandre Benoit, Hervé Bredin, Georges  Quénot, Patrick  Lambert
<p><em>ECCV 2012, Workshop on Information Fusion in Computer Vision for Concept Recognition</em></p>
<blockquote><p>We deal with the issue of combining dozens of classifiers into a better one, for concept detection in videos. We compare three fusion approaches that share a common structure: they all start with a classifier clustering stage, continue with an intra-cluster fusion and end with an inter-cluster fusion. The main difference between them comes from the first stage. The first approach relies on a priori knowledge about the internals of each classifier (low-level descriptors and classification algorithm) to group the set of available classifiers by similarity. The second and third approaches obtain classifier similarity measures directly from their output and group them using agglomerative clustering for the second approach and community detection for the third one.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Strat2012']);">.bib</a> [Strat2012] | <i class="icon-book"></i> <a href="/download/pdfs/Strat2012.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Strat2012']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseErcolessi2012b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ercolessi2012b']);">
        Hierarchical Framework for Plot De-interlacing of TV Series based on Speakers, Dialogues and Images
        </a>
    </div>
    <div id="collapseErcolessi2012b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Sandrine Mouysset, Hervé Bredin
<p><em>AMVA 2012, 1st ACM International Workshop on Audio and Multimedia Methods for Large-Scale Video Analysis at ACM Multimedia 2012</em></p>
<blockquote><p>Since the 90s, TV series tend to introduce more and more main characters and they are often composed of multiple intertwined stories. In this paper, we propose a hierarchical framework of plot de-interlacing  which permits to cluster semantic scenes into stories: a story is a group of scenes not necessarily contiguous but showing a strong semantic relation. Each scene is described using three different modalities (based on color histograms, speaker diarization or automatic speech recognition outputs) as well as their multimodal combination. We introduce the notion of character-driven episodes as episodes where stories are emphasized by the presence or absence of characters, and we propose an automatic method, based on a social graph, to detect these episodes. Depending on whether an episode is character-driven or not, the plot-de-interlacing -which is a scene clustering- is made either through a  traditional average-link agglomerative clustering with speaker modality only, either through a  spectral clustering with the fusion of all modalities. Experiments, conducted on twenty three episodes from three quite different TV series (different lengths and formats), show that the hierarchical framework brings an improvement for all the series.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ercolessi2012b']);">.bib</a> [Ercolessi2012b] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ercolessi2012b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseErcolessi2012c_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ercolessi2012c']);">
        StoViz: Story Visualization of TV Series
        </a>
    </div>
    <div id="collapseErcolessi2012c_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Hervé Bredin, Christine Sénac
<p><em>ACM MM 2012, 20th ACM International Conference on Multimedia</em></p>
<blockquote><p>Recent TV series tend to have more and more complex plot. They follow the lives of numerous characters and are made of multiple intertwined stories. In this paper, we introduce StoViz, a web-based interface allowing a fast overview of this kind of episode structure, based on our plot de-interlacing system. StoViz has two main goals. First, it provides the user with a useful overview of the episode by displaying each story separately and a short abstract extracted from them. Then, it allows an efficient visual comparison of the output of any automatic plot de-interlacing algorithm with the manual annotation in terms of stories and is therefore very helpful for evaluation purposes. StoViz is available online at http://stoviz.niderb.fr.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ercolessi2012c']);">.bib</a> [Ercolessi2012c] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012c.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ercolessi2012c']);">.pdf</a>        </div>
    </div>
</div>
<h3>2011</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseGorisse2011_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Gorisse2011']);">
        IRIM at TRECVID 2010: Semantic Indexing and Instance Search
        </a>
    </div>
    <div id="collapseGorisse2011_All" class="accordion-body collapse">
        <div class="accordion-inner">
        David Gorisse, Frédéric Precioso, Philippe Gosselin, Lionel Granjon, Denis Pellerin, Michèle Rombaut, Hervé Bredin, Lionel Koenig, Rémi Vieux, Boris Mansencal, Jenny Benois-Pineau, Hugo Boujut, Claire Morand, Hervé Jégou, Stéphane Ayache, Bahjat Safadi, Yubing Tong, Franck Thollard, Georges Quénot, Matthieu Cord, Alexandre Beno\^it, Patrick Lambert
<p><em>TRECVid 2010, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes our participation to the TRECVID 2010 semantic indexing and instance search tasks. For the semantic indexing task, we evaluated a number of different descriptors and tried different fusion strategies, in particular hierarchical fusion. The best IRIM run has a Mean Inferred Average Precision of 0.0442, which is above the task median performance. We found that fusion of the classification scores from different classifier types improves the performance and that even with a quite low individual performance, audio descriptors can help. For the instance search task, we used only one of the example images in our queries. The rank is nearly in the middle of the list of participants. The experiment showed that HSV features outperform the concatenation of HSV and Edge histograms or the Wavelet features.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Gorisse2011']);">.bib</a> [Gorisse2011] | <i class="icon-book"></i> <a href="/download/pdfs/Gorisse2011.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Gorisse2011']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseErcolessi2011_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ercolessi2011']);">
        Segmenting TV Series into Scenes using Speaker Diarization
        </a>
    </div>
    <div id="collapseErcolessi2011_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Hervé Bredin, Christine Sénac, Philippe Joly
<p><em>WIAMIS 2011, 12th International Workshop on Image Analysis for Multimedia Interactive Services</em></p>
<blockquote><p>In this paper, we propose a novel approach to perform scene segmentation of TV series. Using the output of our existing speaker diarization system, any temporal segment of the video can be described as a binary feature vector. A straightforward segmentation algorithm then allows to group similar contiguous speaker segments into scenes. An additional visual-only color-based segmentation is then used to refine the first segmentation. Experiments are performed on a subset of the Ally McBeal TV series and show promising results, obtained with a rule-free and generic method. For comparison purposes, test corpus annotations and description are made available to the community.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ercolessi2011']);">.bib</a> [Ercolessi2011] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2011.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ercolessi2011']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseRamona2011_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ramona2011']);">
        A Public Audio Identification Evaluation Framework for Broadcast Monitoring
        </a>
    </div>
    <div id="collapseRamona2011_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Mathieu Ramona, Sébastien Fenet, Raphaël Blouet, Hervé Bredin, Thomas Fillon, Geoffroy Peeters
<p><em>Applied Artificial Intelligence</em></p>
<blockquote><p>This paper presents the first public framework for the evaluation of audio fingerprinting techniques. Although the domain of audio identification is very active, both in the industry and the academic world, there is nowadays no common basis to compare the proposed techniques. This is because corpuses and evaluation protocols differ between the authors. The framework we present here corresponds to a use-case in which audio excerpts have to be detected in a radio broadcast stream. This scenario indeed naturally provides a large variety of audio distortions that makes this task a real challenge for fingerprinting systems. Scoring metrics are discussed, with regard to this particular scenario. We then describe a whole evaluation framework including an audio corpus, along with the related groundtruth annotation, and a toolkit for the computation of the score metrics. An example of application of this framework is finally detailed. This took place during the evaluation campaign of the Quaero project. This evaluation framework is publicly available for download and constitutes a simple, yet thorough, platform that can be used by the community in the field of audio identification, to encourage reproducible results.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ramona2011']);">.bib</a> [Ramona2011] | <i class="icon-book"></i> <a href="/download/pdfs/Ramona2011.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ramona2011']);">.pdf</a>        </div>
    </div>
</div>
<h3>2010</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseDelezoide2010_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Delezoide2010']);">
        IRIM at TRECVID 2009: High Level Feature Extraction
        </a>
    </div>
    <div id="collapseDelezoide2010_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Delezoide, Bertrand, Le Borgne, Hervé, Moëllic, Pierre-Alain, Gorisse, David, Precioso, Frédéric, Wang, Feng, Merialdo, Bernard, Gosselin, Philippe, Granjon, Lionel, Pellerin, Denis, Rombaut, Michèle, Bredin, Hervé, Koenig, Lionel, Lachambre, Hélène, El Khoury, Elie, Mansencal, Boris, Zhou, Yifan, Benois-Pineau, Jenny, Jégou, Hervé, Ayache, Stéphane, Safadi, Bahjat, Quenot, Georges, Fabrizio, Jonathan, Cord, Matthieu, Glotin, Hervé, Zhao, Zhongqiu, Dumont, Emilie, Augereau, Bertrand
<p><em>TRECVid 2009, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes our participation to the TRECVID 2009 High Level Features detection task. We evaluated a large number of different descriptors (on TRECVID 2008 data) and tried different fusion strategies, in particular hierarchical fusion and genetic fusion. The best IRIM run has a Mean Inferred Average Precision of 0.1220, which is significantly above TRECVID 2009 HLF detection task median performance. We found that fusion of the classification scores from different classifier types improves the performance and that even with a quite low individual performance, audio descriptors can help.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Delezoide2010']);">.bib</a> [Delezoide2010] | <i class="icon-book"></i> <a href="/download/pdfs/Delezoide2010.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Delezoide2010']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2010_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2010']);">
        IRIT at TRECVID HLF 2009: Audio to the Rescue
        </a>
    </div>
    <div id="collapseBredin2010_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Lionel Koenig, Hélène Lachambre, Elie El Khoury
<p><em>TRECVid 2009, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2010']);">.bib</a> [Bredin2010] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2010.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2010']);">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2009_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2009']);">
        Talking-Face Authentication
        </a>
    </div>
    <div id="collapseBredin2009_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Aurélien Mayoue, Gérard Chollet, Bernadette Dorizzi
<p><em>Guide to Biometric Reference Systems and Performance Evaluation</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2009']);">.bib</a> [Bredin2009] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2009.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2009']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseKaram2009_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Karam2009']);">
        Talking-Face Identity Verification, Audiovisual Forgery and Robustness Issues
        </a>
    </div>
    <div id="collapseKaram2009_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Walid Karam, Hervé Bredin, Hanna Greige, Gérard Chollet, Chafic Mokbel
<p><em>EURASIP Journal on Advances in Signal Processing, Special Issue on Recent Advances in Biometric Systems: A Signal Processing Perspective</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Karam2009']);">.bib</a> [Karam2009] | <i class="icon-book"></i> <a href="/download/pdfs/Karam2009.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Karam2009']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseCooray2009_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Cooray2009']);">
        An Interactive and Multi-Level Framework for Summarising User-Generated Videos
        </a>
    </div>
    <div id="collapseCooray2009_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Saman H. Cooray, Hervé Bredin, Li-Qun Xu, Noel E. O'Connor
<p><em>ACM MM 2009, 17th ACM International Conference on Multimedia</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Cooray2009']);">.bib</a> [Cooray2009] | <i class="icon-book"></i> <a href="/download/pdfs/Cooray2009.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Cooray2009']);">.pdf</a>        </div>
    </div>
</div>
<h3>2008</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2008_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2008']);">
        Making Talking-Face Authentication Robust to Deliberate Imposture
        </a>
    </div>
    <div id="collapseBredin2008_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>ICASSP 2008, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2008']);">.bib</a> [Bredin2008] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2008.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2008']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseFauve2008_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Fauve2008']);">
        Some Results from the BioSecure Talking-Face Evaluation Campaign
        </a>
    </div>
    <div id="collapseFauve2008_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Benoït Fauve, Hervé Bredin, Walid Karam, Florian Verdet, Aurélien Mayoue, Gérard Chollet, Jean Hennebert, R. Lewis, John Mason, Chafic Mokbel, Dijana Petrovska
<p><em>ICASSP 2008, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Fauve2008']);">.bib</a> [Fauve2008] | <i class="icon-book"></i> <a href="/download/pdfs/Fauve2008.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Fauve2008']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseDumont2008_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Dumont2008']);">
        Rushes Video Summarization using a Collaborative Approach
        </a>
    </div>
    <div id="collapseDumont2008_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Emilie Dumont, Bernard Merialdo, Slim Essid, Werner Bailer, Herwig Rehatschek, Daragh Byrne, Hervé Bredin, Noel O'Connor, Gareth JF Jones, Alan F Smeaton, Martin Haller, Andreas Krutz, Thomas Sikora, Tomas Piatrik
<p><em>TRECVID 2008, ACM International Conference on Multimedia Information Retrieval</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Dumont2008']);">.bib</a> [Dumont2008] | <i class="icon-book"></i> <a href="/download/pdfs/Dumont2008.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Dumont2008']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2008a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2008a']);">
        Dublin City University at TRECVid 2008 BBC Rushes Summarisation Task
        </a>
    </div>
    <div id="collapseBredin2008a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Daragh Byrne, Hyowon Lee, Noel O'Connor, Gareth JF Jones
<p><em>TRECVID 2008, ACM International Conference on Multimedia Information Retrieval 2008</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2008a']);">.bib</a> [Bredin2008a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2008a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2008a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseDumont2008a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Dumont2008a']);">
        A Collaborative Approach to Video Summarization
        </a>
    </div>
    <div id="collapseDumont2008a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Emilie Dumont, Bernard Merialdo, Slim Essid, Werner Bailer, Daragh Byrne, Hervé Bredin, Noel O'Connor, Gareth JF Jones, Martin Haller, Andreas Krutz, Thomas Sikora, Tomas Piatrik
<p><em>SAMT 2008, 3rd International Conference on Semantic and Digital Media Technologies</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Dumont2008a']);">.bib</a> [Dumont2008a] | <i class="icon-book"></i> <a href="/download/pdfs/Dumont2008a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Dumont2008a']);">.pdf</a>        </div>
    </div>
</div>
<h3>2007</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2007_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2007']);">
        Audio-Visual Speech Synchrony Measure: Application to Biometrics
        </a>
    </div>
    <div id="collapseBredin2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>EURASIP Journal on Advances in Signal Processing, Special Issue on Knowledge-Assisted Media Analysis for Interactive Multimedia Applications</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2007']);">.bib</a> [Bredin2007] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2007']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2007a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2007a']);">
        Audio-Visual Speech Synchrony Measure for Talking-Face Identity Verification
        </a>
    </div>
    <div id="collapseBredin2007a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>ICASSP 2007, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2007a']);">.bib</a> [Bredin2007a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2007a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2007a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLandais2007_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Landais2007']);">
        Vérification Audiovisuelle de l'Identité
        </a>
    </div>
    <div id="collapseLandais2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Rémi Landais, Hervé Bredin, Leila Zouari, Gérard Chollet
<p><em>Traitement et Analyse de l'Information : Méthodes et Applications</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Landais2007']);">.bib</a> [Landais2007] | <i class="icon-book"></i> <a href="/download/pdfs/Landais2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Landais2007']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseArgones-Rua2007_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Argones-Rua2007']);">
        Aliveness Detection using Coupled Hidden Markov Models
        </a>
    </div>
    <div id="collapseArgones-Rua2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Enrique Argones-Rúa, Carmen García-Mateo, Hervé Bredin, Gérard Chollet
<p><em>1st Spanish Workshop on Biometrics</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Argones-Rua2007']);">.bib</a> [Argones-Rua2007] | <i class="icon-book"></i> <a href="/download/pdfs/Argones-Rua2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Argones-Rua2007']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsePerrot2007_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Perrot2007']);">
        Biometrics and Forensic Sciences: the Same Quest for Identification?
        </a>
    </div>
    <div id="collapsePerrot2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Patrick Perrot, Hervé Bredin, Gérard Chollet
<p><em>2007 International Crime Science Conference</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Perrot2007']);">.bib</a> [Perrot2007] | <i class="icon-book"></i> <a href="/download/pdfs/Perrot2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Perrot2007']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2007b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2007b']);">
        Vérification de l'Identité d'un Visage Parlant. Apport de la Mesure de Synchronie Audiovisuelle face aux Tentatives Délibérées d'Imposture.
        </a>
    </div>
    <div id="collapseBredin2007b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2007b']);">.bib</a> [Bredin2007b] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2007b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2007b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseArgones-Rua2007a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Argones-Rua2007a']);">
        Audio-Visual Speech Asynchrony Detection using Co-Inertia Analysis and Coupled Hidden Markov Models
        </a>
    </div>
    <div id="collapseArgones-Rua2007a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Enrique Argones-Rúa, Hervé Bredin, Carmen García-Mateo, Gérard Chollet, Daniel González-Jiménez
<p><em>Pattern Analysis and Applications Journal</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Argones-Rua2007a']);">.bib</a> [Argones-Rua2007a] | <i class="icon-book"></i> <a href="/download/pdfs/Argones-Rua2007a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Argones-Rua2007a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseChollet2007_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Chollet2007']);">
        Some Experiments in Audio-Visual Speech Processing
        </a>
    </div>
    <div id="collapseChollet2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Gérard Chollet, Rémi Landais, Hervé Bredin, Thomas Hueber, Chafic Mokbel, Patrick Perrot, Leila Zouari
<p><em>Non-Linear Speech Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Chollet2007']);">.bib</a> [Chollet2007] | <i class="icon-book"></i> <a href="/download/pdfs/Chollet2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Chollet2007']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseAbboud2007_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Abboud2007']);">
        Audio-Visual Identity Verification: an Introductory Overview
        </a>
    </div>
    <div id="collapseAbboud2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Bouchra Abboud, Hervé Bredin, Guido Aversano, Gérard Chollet
<p><em>Progress in Nonlinear Speech Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Abboud2007']);">.bib</a> [Abboud2007] | <i class="icon-book"></i> <a href="/download/pdfs/Abboud2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Abboud2007']);">.pdf</a>        </div>
    </div>
</div>
<h3>2006</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2006_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2006']);">
        Detecting Replay Attacks in Audiovisual Identity Verification
        </a>
    </div>
    <div id="collapseBredin2006_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Antonio Miguel, Ian Witten, Gérard Chollet
<p><em>ICASSP 2006, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2006']);">.bib</a> [Bredin2006] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2006']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseKoreman2006_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Koreman2006']);">
        Multi-Modal Biometric Authentication on the SecurePhone PDA
        </a>
    </div>
    <div id="collapseKoreman2006_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Jacques Koreman, Andrew C Morris, D. Wu, Sabah Jassim, Harin Sellahewa, J. Ehlers, Gérard Chollet, Guido Aversano, Hervé Bredin, Sonia Garcia-Salicetti, Lorène Allano, Bao Ly Van, Bernadette Dorizzi
<p><em>MMUA 2006, Workshop on Multimodal User Authentication</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Koreman2006']);">.bib</a> [Koreman2006] | <i class="icon-book"></i> <a href="/download/pdfs/Koreman2006.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Koreman2006']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2006a_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2006a']);">
        The BioSecure Talking-Face Reference System
        </a>
    </div>
    <div id="collapseBredin2006a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Guido Aversano, Chafic Mokbel, Gérard Chollet
<p><em>MMUA 2006, Workshop on Multimodal User Authentication</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2006a']);">.bib</a> [Bredin2006a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2006a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBrugger2006_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Brugger2006']);">
        Reconnaissance Audiovisuelle de la Parole par VMike
        </a>
    </div>
    <div id="collapseBrugger2006_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Fabian Brugger, Leila Zouari, Hervé Bredin, Asma Amehraye, Gérard Chollet, Dominique Pastor, Yang Ni
<p><em>JEP 2006, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Brugger2006']);">.bib</a> [Brugger2006] | <i class="icon-book"></i> <a href="/download/pdfs/Brugger2006.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Brugger2006']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2006b_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2006b']);">
        GMM-based SVM for Face Recognition
        </a>
    </div>
    <div id="collapseBredin2006b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Najim Dehak, Gérard Chollet
<p><em>ICPR 2006, IAPR International Conference on Pattern Recognition</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2006b']);">.bib</a> [Bredin2006b] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2006b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2006c_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2006c']);">
        Measuring Audio and Visual Speech Synchrony: Methods and Applications
        </a>
    </div>
    <div id="collapseBredin2006c_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>VIE 2006, IEE International Conference on Visual Information Engineering</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2006c']);">.bib</a> [Bredin2006c] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006c.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2006c']);">.pdf</a>        </div>
    </div>
</div>
<h3>2005</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseMcTait2005_All" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'McTait2005']);">
        Adapting a High Quality Audiovisual Database to PDA Quality
        </a>
    </div>
    <div id="collapseMcTait2005_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Kevin McTait, Hervé Bredin, Silvia Colón, Thomas Fillon, Gérard Chollet
<p><em>ISISPA 2005, International Symposium on Image and Signal Processing and Analysis</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'McTait2005']);">.bib</a> [McTait2005] | <i class="icon-book"></i> <a href="/download/pdfs/McTait2005.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'McTait2005']);">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
<div class="tab-pane fade in" id="Journalarticles">
<div class="accordion" id="accordionJournalarticles">
<h3>2014</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseRoy2014_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Roy2014']);">
        Lexical Speaker Identification in TV Shows
        </a>
    </div>
    <div id="collapseRoy2014_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Anindya Roy, Hervé Bredin, William Hartmann, Viet-Bac Le, Claude Barras, Jean-Luc Gauvain
<p><em>Multimedia Tools and Applications</em></p>
<blockquote><p>It is possible to use lexical information extracted from speech transcripts for speaker identification (SID), either on its own or to improve the performance of standard cepstral-based SID systems upon fusion. This was established before typically using isolated speech from single speakers (NIST SRE corpora, parliamentary speeches). On the contrary, this work applies lexical approaches for SID on a different type of data. It uses the REPERE corpus consisting of unsegmented multiparty conversations, mostly debates, discussions and Q&A sessions from TV shows. It is hypothesized that people give out clues to their identity when speaking in such settings which this work aims to exploit. The impact on SID performance of the diarization front-end required to pre-process the unsegmented data is also measured. Four lexical SID approaches are studied in this work, including TFIDF, BM25 and LDA-based topic modeling. Results are analysed in terms of TV shows and speaker roles. Lexical approaches achieve low error rates for certain speaker roles such as anchors and journalists, sometimes lower than a standard cepstral-based Gaussian Supervector -- Support Vector Machine (GSV-SVM) system. Also, in certain cases, the lexical system shows modest improvement over the cepstral-based system performance using score-level sum fusion. To highlight the potential of using lexical information not just to improve upon cepstral-based SID systems but as an independent approach in its own right, initial studies on crossmedia SID is briefly reported. Instead of using speech data as all cepstral systems require, this approach uses Wikipedia texts to train lexical speaker models which are then tested on speech transcripts to identify speakers.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Roy2014']);">.bib</a> [Roy2014] | <i class="icon-book"></i> <a href="/download/pdfs/Roy2014.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Roy2014']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseBredin2014_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2014']);">
        Person Instance Graphs for Mono-, Cross- and Multi-Modal Person Recognition in Multimedia Data. Application to Speaker Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseBredin2014_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Anindya Roy, Viet-Bac Le, Claude Barras
<p><em>International Journal of Multimedia Information Retrieval</em></p>
<blockquote><p>This work introduces a unified framework for mono-, cross- and multi-modal person recognition in multimedia data. Dubbed Person Instance Graph, it models the person recognition task as a graph mining problem: i.e. finding the best mapping between person instance vertices and identity vertices. Practically, we describe how the approach can be applied to speaker identification in TV broadcast. Then, a solution to the above-mentioned mapping problem is proposed. It relies on Integer Linear Programming to model the problem of clustering person instances based on their identity. We provide an in-depth theoretical definition of the optimization problem. Moreover, we improve two fundamental aspects of our previous related work: the problem constraints and the optimized objective function. Finally, a thorough experimental evaluation of the proposed framework is performed on a publicly available benchmark database. Depending on the graph configuration (i.e. the choice of its vertices and edges), we show that multiple tasks can be addressed interchangeably (e.g. speaker diarization, supervised or unsupervised speaker identification), significantly outperforming state-of-the-art mono-modal approaches.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2014']);">.bib</a> [Bredin2014] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2014.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2014']);">.pdf</a>        </div>
    </div>
</div>
<h3>2012</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseErcolessi2012a_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ercolessi2012a']);">
        Vers un Résumé Automatique de Séries Télévisées basé sur une Recherche Multimodale d'Histoires
        </a>
    </div>
    <div id="collapseErcolessi2012a_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Hervé Bredin, Sandrine Mouysset
<p><em>Document Numérique -- Numéro Spécial ``Résumé Automatique des Documents''</em></p>
<blockquote><p>Modern TV series have complex plots made of several intertwined stories following numerous characters. In this paper, we propose an approach for automatically detecting these stories in order to generate video summaries and we propose a visualization tool to have a quick and easy look at TV series. Based on automatic scene segmentation of each TV series episode (a scene is defined as temporally and spatially continuous and semantically coherent), scenes are clustered into stories, made of (non necessarily adjacent) semantically similar scenes. Visual, audio and text modalities are combined to achieve better scene segmentation and story detection performance. An extraction of salient scenes from stories is performed to create the summary. Experimentations are conducted on two TV series with different formats.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ercolessi2012a']);">.bib</a> [Ercolessi2012a] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ercolessi2012a']);">.pdf</a>        </div>
    </div>
</div>
<h3>2011</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseRamona2011_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ramona2011']);">
        A Public Audio Identification Evaluation Framework for Broadcast Monitoring
        </a>
    </div>
    <div id="collapseRamona2011_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Mathieu Ramona, Sébastien Fenet, Raphaël Blouet, Hervé Bredin, Thomas Fillon, Geoffroy Peeters
<p><em>Applied Artificial Intelligence</em></p>
<blockquote><p>This paper presents the first public framework for the evaluation of audio fingerprinting techniques. Although the domain of audio identification is very active, both in the industry and the academic world, there is nowadays no common basis to compare the proposed techniques. This is because corpuses and evaluation protocols differ between the authors. The framework we present here corresponds to a use-case in which audio excerpts have to be detected in a radio broadcast stream. This scenario indeed naturally provides a large variety of audio distortions that makes this task a real challenge for fingerprinting systems. Scoring metrics are discussed, with regard to this particular scenario. We then describe a whole evaluation framework including an audio corpus, along with the related groundtruth annotation, and a toolkit for the computation of the score metrics. An example of application of this framework is finally detailed. This took place during the evaluation campaign of the Quaero project. This evaluation framework is publicly available for download and constitutes a simple, yet thorough, platform that can be used by the community in the field of audio identification, to encourage reproducible results.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ramona2011']);">.bib</a> [Ramona2011] | <i class="icon-book"></i> <a href="/download/pdfs/Ramona2011.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ramona2011']);">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseKaram2009_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Karam2009']);">
        Talking-Face Identity Verification, Audiovisual Forgery and Robustness Issues
        </a>
    </div>
    <div id="collapseKaram2009_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Walid Karam, Hervé Bredin, Hanna Greige, Gérard Chollet, Chafic Mokbel
<p><em>EURASIP Journal on Advances in Signal Processing, Special Issue on Recent Advances in Biometric Systems: A Signal Processing Perspective</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Karam2009']);">.bib</a> [Karam2009] | <i class="icon-book"></i> <a href="/download/pdfs/Karam2009.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Karam2009']);">.pdf</a>        </div>
    </div>
</div>
<h3>2007</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseBredin2007_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2007']);">
        Audio-Visual Speech Synchrony Measure: Application to Biometrics
        </a>
    </div>
    <div id="collapseBredin2007_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>EURASIP Journal on Advances in Signal Processing, Special Issue on Knowledge-Assisted Media Analysis for Interactive Multimedia Applications</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2007']);">.bib</a> [Bredin2007] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2007']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseArgones-Rua2007a_Journalarticles" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Argones-Rua2007a']);">
        Audio-Visual Speech Asynchrony Detection using Co-Inertia Analysis and Coupled Hidden Markov Models
        </a>
    </div>
    <div id="collapseArgones-Rua2007a_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Enrique Argones-Rúa, Hervé Bredin, Carmen García-Mateo, Gérard Chollet, Daniel González-Jiménez
<p><em>Pattern Analysis and Applications Journal</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Argones-Rua2007a']);">.bib</a> [Argones-Rua2007a] | <i class="icon-book"></i> <a href="/download/pdfs/Argones-Rua2007a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Argones-Rua2007a']);">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
<div class="tab-pane fade in" id="Bookchapters">
<div class="accordion" id="accordionBookchapters">
<h3>2014</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionBookchapters" href="#collapseStrat2014_Bookchapters" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Strat2014']);">
        Hierarchical Late Fusion for Concept Detection in Videos
        </a>
    </div>
    <div id="collapseStrat2014_Bookchapters" class="accordion-body collapse">
        <div class="accordion-inner">
        Sabin Tiberius Strat, Alexandre Benoit, Patrick Lambert, Hervé Bredin, Georges Quénot
<p><em>Fusion in Computer Vision -- Understanding Complex Visual Content</em></p>
<blockquote><p>Current research shows that the detection of semantic concepts (animal, bus, person, dancing etc.) in multimedia documents such as videos, requires the use of several types of complementary descriptors in order to achieve good results. In this work, we explore strategies for combining dozens of complementary content descriptors (or ``experts'') in an efficient way, through the use of late fusion approaches, for concept detection in multimedia documents. We explore two fusion approaches that share a common structure: both start with a clustering of experts stage, continue with an intra-cluster fusion and finish with an inter-cluster fusion, and we also experiment with other state-of-the-art methods. The first fusion approach relies on a priori knowledge about the internals of each expert to group the set of available experts by similarity. The second approach automatically obtains measures on the similarity of experts from their output to group the experts using agglomerative clustering, and then combines the results of this fusion with those from other methods. In the end, we show that an additional performance boost can be obtained by also considering the context of multimedia elements.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Strat2014']);">.bib</a> [Strat2014] | <i class="icon-book"></i> <a href="/download/pdfs/Strat2014.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Strat2014']);">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionBookchapters" href="#collapseBredin2009_Bookchapters" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2009']);">
        Talking-Face Authentication
        </a>
    </div>
    <div id="collapseBredin2009_Bookchapters" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Aurélien Mayoue, Gérard Chollet, Bernadette Dorizzi
<p><em>Guide to Biometric Reference Systems and Performance Evaluation</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2009']);">.bib</a> [Bredin2009] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2009.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2009']);">.pdf</a>        </div>
    </div>
</div>
<h3>2007</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionBookchapters" href="#collapseChollet2007_Bookchapters" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Chollet2007']);">
        Some Experiments in Audio-Visual Speech Processing
        </a>
    </div>
    <div id="collapseChollet2007_Bookchapters" class="accordion-body collapse">
        <div class="accordion-inner">
        Gérard Chollet, Rémi Landais, Hervé Bredin, Thomas Hueber, Chafic Mokbel, Patrick Perrot, Leila Zouari
<p><em>Non-Linear Speech Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Chollet2007']);">.bib</a> [Chollet2007] | <i class="icon-book"></i> <a href="/download/pdfs/Chollet2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Chollet2007']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionBookchapters" href="#collapseAbboud2007_Bookchapters" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Abboud2007']);">
        Audio-Visual Identity Verification: an Introductory Overview
        </a>
    </div>
    <div id="collapseAbboud2007_Bookchapters" class="accordion-body collapse">
        <div class="accordion-inner">
        Bouchra Abboud, Hervé Bredin, Guido Aversano, Gérard Chollet
<p><em>Progress in Nonlinear Speech Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Abboud2007']);">.bib</a> [Abboud2007] | <i class="icon-book"></i> <a href="/download/pdfs/Abboud2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Abboud2007']);">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
<div class="tab-pane fade in" id="Conferenceandworkshopproceedings">
<div class="accordion" id="accordionConferenceandworkshopproceedings">
<h3>2015</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseCharlet2015_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Charlet2015']);">
        What Makes a Speaker Recognizable in TV Broadcast? Going Beyond Speaker Identification Error Rate
        </a>
    </div>
    <div id="collapseCharlet2015_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Delphine Charlet, Johann Poignant, Hervé Bredin, Corinne Fredouille, Sylvain Meignier
<p><em>ERRARE 2015, Second Workshop on Errors By Humans and Machines in Multimedia, Multimodal, and Multilingual Data Processing</em></p>
<blockquote><p>Speaker identification approaches for TV broadcast are usually evaluated and compared based on global error rates derived from the overall duration of missed detection, false alarm and confusion. Based on the analysis of the output of the systems submitted to the final round of the French evaluation campaign REPERE, this paper highlights the fact that these average metrics lead to the incorrect intuition that current state-of-the-art algorithms partially recognize all speakers. Setting aside incorrect diarization and adverse acoustic conditions, we show that their performance is in fact essentially bi-modal: in a given show, either all speech turns of a speaker are correctly identified or none of them are. We then proceed with trying to understand and explain this behavior, through perfomance prediction experiments. These experiments show that the most discriminant speaker characteristics are -- first -- their total speech duration in the current show and -- then only -- the amount of training data available to build their acoustic model.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Charlet2015']);">.bib</a> [Charlet2015] | <i class="icon-book"></i> <a href="/download/pdfs/Charlet2015.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Charlet2015']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseKnyazeva2015_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Knyazeva2015']);">
        Structured Prediction for Speaker Identification in TV Series
        </a>
    </div>
    <div id="collapseKnyazeva2015_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Elena Knyazeva, Guillaume Wisniewski, Hervé Bredin, Fran\ccois Yvon
<p><em>Interspeech 2015, 16th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>Though radio and TV broadcast are highly structured documents, state-of-the-art speaker identification algorithms do not take advantage of this information to improve prediction performance: speech turns are usually identified independently from each other, using unstructured multi-class classification approaches. In this work, we propose to address speaker identification as a sequence labeling task and use two structured prediction techniques to account for the inherent temporal structure of interactions between speakers: the first one relies on Conditional Random Field and can take into account local relations between two consecutive speech turns; the second one, based on the SEARN framework, sacrifices exact inference for the sake of the expressiveness of the model and is able to incorporate rich structure information during prediction. Experiments performed on The Big Bang Theory TV series show that structured prediction techniques outperform the  standard unstructured approach.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Knyazeva2015']);">.bib</a> [Knyazeva2015] | <i class="icon-book"></i> <a href="/download/pdfs/Knyazeva2015.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Knyazeva2015']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBudnik2015_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Budnik2015']);">
        Collaborative Annotation for Person Identification in TV Shows
        </a>
    </div>
    <div id="collapseBudnik2015_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<p><em>Interspeech 2015, 16th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>This paper presents a collaborative annotation framework for person identification in TV shows. The web annotation front-end will be demonstrated during the Show and Tell session. All the code for annotation is made available on github. The tool can also be used in a crowd-sourcing environment.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Budnik2015']);">.bib</a> [Budnik2015] | <i class="icon-book"></i> <a href="/download/pdfs/Budnik2015.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Budnik2015']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsePoignant2015_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Poignant2015']);">
        Multimodal Person Discovery in Broadcast TV at MediaEval 2015
        </a>
    </div>
    <div id="collapsePoignant2015_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Johann Poignant, Hervé Bredin, Claude Barras
<p><em>MediaEval 2015</em></p>
<blockquote><p>We describe the ``Multimodal Person Discovery in Broadcast TV'' task of MediaEval 2015 benchmarking initiative. Participants are asked to return the names of people who can be both seen as well as heard in every shot of a collection of videos. The list of people is not known a priori and their names must be discovered in an unsupervised way from media content using text overlay or speech transcripts. The task is evaluated using information retrieval metrics, based on a posteriori collaborative annotation of the test corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Poignant2015']);">.bib</a> [Poignant2015] | <i class="icon-book"></i> <a href="/download/pdfs/Poignant2015.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Poignant2015']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsePoignant2015a_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Poignant2015a']);">
        LIMSI @ MediaEval 2015: Person Discovery in Broadcast TV Task
        </a>
    </div>
    <div id="collapsePoignant2015a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Johann Poignant, Hervé Bredin, Claude Barras
<p><em>MediaEval 2015</em></p>
<blockquote><p>This paper describes the algorithm tested by the LIMSI team in the MediaEval 2015 Person Discovery in Broadcast TV Task. For this task we used an audio/video diarization process constrained by names written on screen. These names are used to both identify clusters and prevent the fusion of two clusters with different co-occurring names. This method obtained 83.1% of EwMAP tuned on the out-domain development corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Poignant2015a']);">.bib</a> [Poignant2015a] | <i class="icon-book"></i> <a href="/download/pdfs/Poignant2015a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Poignant2015a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBruneau2015_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bruneau2015']);">
        A Visual Analytics Approach to Finding Factors Improving Automatic Speaker Identification
        </a>
    </div>
    <div id="collapseBruneau2015_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Pierrick Bruneau, Mickaël Stefas, Hervé Bredin, Johann Poignant, Thomas Tamisier, Claude Barras
<p><em>ICMI 2015, 17th International Conference on Multimodal Interaction</em></p>
<blockquote><p>Classification quality criteria such as precision, recall, and F-measure are generally the basis for evaluating contributions in automatic speaker recognition. Specifically, comparisons are carried out mostly via mean values estimated on a set of media. Whilst this approach is relevant to assess improvement w.r.t. the state-of-the-art, or ranking participants in the context of an automatic annotation challenge, it gives little insight to system designers in terms of cues for improving algorithms, hypothesis formulation, and evidence display. This paper presents a design study of a visual and interactive approach to analyze errors made by automatic annotation algorithms. A timeline-based tool emerged from prior steps of this study. A critical review, driven by user interviews, exposes caveats and refines user objectives. The next step of the study is then initiated by sketching designs combining elements of the current prototype to principles newly identified as relevant.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bruneau2015']);">.bib</a> [Bruneau2015] | <i class="icon-book"></i> <a href="/download/pdfs/Bruneau2015.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bruneau2015']);">.pdf</a>        </div>
    </div>
</div>
<h3>2014</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseRoy2014a_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Roy2014a']);">
        TVD: a Reproducible and Multiply Aligned TV Series Dataset
        </a>
    </div>
    <div id="collapseRoy2014a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Anindya Roy, Camille Guinaudeau, Hervé Bredin, Claude Barras
<p><em>LREC 2014, 9th Language Resources and Evaluation Conference</em></p>
<blockquote><p>We present a new dataset built around two TV series, The Big Bang Theory (a situation comedy) and Game of Thrones (a fantasy drama). It has multiple tracks including dialogue, crowd-sourced textual descriptions and metadata, all time-stamped and temporally aligned with each other. We provide tools to reproduce it for research purposes, provided that one has legally acquired the DVDs of the series. The alignment algorithm used is evaluated on a manually aligned subset of the data.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Roy2014a']);">.bib</a> [Roy2014a] | <i class="icon-book"></i> <a href="/download/pdfs/Roy2014a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Roy2014a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2014a_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2014a']);">
        Person Instance Graphs for Named Speaker Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseBredin2014a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Antoine Laurent, Achintya Sarkar, Viet-Bac Le, Sophie Rosset, Claude Barras
<p><em>Odyssey 2014, The Speaker and Language Recognition Workshop</em></p>
<blockquote><p>We address the problem of named speaker identification in TV broadcast which consists in answering the question ''who speaks when?'' with the real identity of speakers, using person names automatically obtained from speech transcripts. While existing approaches rely on a first speaker diarization step followed by a local name propagation step to speaker clusters, we propose a unified framework called person instance graph where both steps are jointly modeled as a global optimization problem, then solved using integer linear programming. Moreover, when available, acoustic speaker models can be added seamlessly to the graph structure for joint named and acoustic speaker identification - leading to a 10% error decrease (from 45% down to 35%) over a state-of-the-art i-vector speaker identification system on the REPERE TV broadcast corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2014a']);">.bib</a> [Bredin2014a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2014a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2014a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBruneau2014_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bruneau2014']);">
        A Web-based Tool for the Visual Analysis of Media Annotations
        </a>
    </div>
    <div id="collapseBruneau2014_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Pierrick Bruneau, Mickaël Stefas, Hervé Bredin, Anh-Phuong Ta, Thomas Tamisier, Claude Barras
<p><em>iV 2014, 18th International Conference Information Visualisation</em></p>
<blockquote><p>Multimedia annotation algorithms infer localized meta-data in multimedia content, e.g. speakers or appearing faces. There is a growing need of experts from this domain to perform advanced analyses, that go beyond medium-scale quality metrics. This paper describes a novel visual tool, that applies interactive visualization principles to the multimedia expert concerns. Multiple coordinated views, augmented by interactive inspection facilities, ease the navigation in media annotations, and the visual detection of relevant information. The effectiveness of the proposition is demonstrated by experimental scenarios on a real multimedia corpus.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bruneau2014']);">.bib</a> [Bruneau2014] | <i class="icon-book"></i> <a href="/download/pdfs/Bruneau2014.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bruneau2014']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBruneau2014a_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bruneau2014a']);">
        Collaborative Annotation of Multimedia Resources
        </a>
    </div>
    <div id="collapseBruneau2014a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Pierrick Bruneau, Mickaël Stefas, Mateusz Budnik, Johann Poignant, Hervé Bredin, Thomas Tamisier, Beno\^it Otjacques
<p><em>CDVE 2014, 11th International Conference on Cooperative Design, Visualization and Engineering</em></p>
<blockquote><p>Reference multimedia corpora for use in automated annotation algorithms are very demanding of manual work. The Camomile project advocates the joint progress of automated annotation methods and tools for improving the benchmark resources. This paper shows some work in progress in interactive visualization of annotations, and perspectives in harnessing the collaboration between manual annotators, algorithm designers, and benchmark administrators.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bruneau2014a']);">.bib</a> [Bruneau2014a] | <i class="icon-book"></i> <a href="/download/pdfs/Bruneau2014a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bruneau2014a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseGuinaudeau2014_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Guinaudeau2014']);">
        LIMSI @ MediaEval SED 2014
        </a>
    </div>
    <div id="collapseGuinaudeau2014_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Camille Guinaudeau, Antoine Laurent, Hervé Bredin
<p><em>MediaEval 2014</em></p>
<blockquote><p>This paper provides an overview of the Social Event Detection (SED) system developed at LIMSI for the 2014 campaign. Our approach is based on a hierarchical agglomerative clustering that uses textual metadata, user-based knowledge and geographical information. These different sources of knowledge, either used separately or in cascade, reach good results for the full clustering subtask with a normalized mutual information equal to 0.95 and F1 scores greater than 0.82 for our best run.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Guinaudeau2014']);">.bib</a> [Guinaudeau2014] | <i class="icon-book"></i> <a href="/download/pdfs/Guinaudeau2014.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Guinaudeau2014']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2014b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2014b']);">
        "Sheldon speaking, bonjour!": Leveraging Multilingual Tracks for (Weakly) Supervised Speaker Identification
        </a>
    </div>
    <div id="collapseBredin2014b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Anindya Roy, Nicolas Pécheux, Alexandre Allauzen
<p><em>ACM MM 2014, 22nd ACM International Conference on Multimedia</em></p>
<blockquote><p>We address the problem of speaker identification in multimedia data, and TV series in particular. While speaker identification is traditionally a supervised machine-learning task, our first contribution is to significantly reduce the need for costly preliminary manual annotations through the use of automatically aligned (and potentially noisy) fan-generated transcripts and subtitles. We show that both speech activity detection and speech turn identification modules trained in this weakly supervised manner achieve similar performance as their fully supervised counterparts (i.e. relying on fine manual speech/non-speech/speaker annotation). Our second contribution relates to the use of multilingual audio tracks usually available with this kind of content to significantly improve the overall speaker identification performance. Reproducible experiments (including dataset, manual annotations and source code) performed on the first six episodes of The Big Bang Theory TV series show that combining the French audio track (containing dubbed actor voices) with the English one (with the original actor voices) improves the overall English speaker identification performance by 5% absolute and up to 70% relative on the five main characters.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2014b']);">.bib</a> [Bredin2014b] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2014b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2014b']);">.pdf</a>        </div>
    </div>
</div>
<h3>2013</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2013_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2013']);">
        Integer Linear Programming for Speaker Diarization and Cross-Modal Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseBredin2013_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Johann Poignant
<p><em>Interspeech 2013, 14th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>Most state-of-the-art approaches address speaker diarization as a hierarchical agglomerative clustering problem in the audio domain. In this paper, we propose to revisit one of them: speech turns clustering based on the Bayesian Information Criterion (a.k.a. BIC clustering). First, we show how to model it as an integer linear programming (ILP) problem.Its resolution leads to the same overall diarization error rate as standard BIC clustering but generates significantly purer speaker clusters. Then, we describe how this approach can easily be extended to the audiovisual domain and TV broadcast in particular. The straightforward integration of detected overlaid names (used to introduce guests or journalists, and obtained via video OCR) into a multimodal ILP problem yields significantly better speaker diarization results. Finally, we explain how this novel paradigm can incidentally be used for unsupervised speaker identification (i.e. not relying on any prior acoustic speaker models). Experiments on the REPERE TV broadcast corpus show that it achieves performance close to that of an oracle capable of identifying any speaker as long as their name appears on screen at least once in the video.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2013']);">.bib</a> [Bredin2013] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2013.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2013']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2013a_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2013a']);">
        QCompere @ REPERE 2013
        </a>
    </div>
    <div id="collapseBredin2013a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Johann Poignant, Guillaume Fortier, Makarand Tapaswi, Viet-Bac Le, Anindya Roy, Claude Barras, Sophie Rosset, Achintya Sarkar, Qian Yang, Hua Gao, Alexis Mignon, Jakob Verbeek, Laurent Besacier, Georges Quénot, Hazim Kemal Ekenel, Rainer Stiefelhagen
<p><em>SLAM 2013, First Workshop on Speech, Language and Audio for Multimedia</em></p>
<blockquote><p>We describe QCompere consortium submissions to the REPERE 2013 evaluation campaign. The REPERE challenge aims at gathering four communities (face recognition, speaker identification, optical character recognition and named entity detection) towards the same goal: multimodal person recognition in TV broadcast. First, four mono-modal components are introduced (one for each foregoing community) constituting the elementary building blocks of our various submissions. Then, depending on the target modality (speaker or face recognition) and on the task (supervised or unsupervised recognition), four different fusion techniques are introduced: they can be summarized as propagation-, classifier-, rule- or graph-based approaches. Finally, their performance is evaluated on REPERE 2013 test set and their advantages and limitations are discussed.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2013a']);">.bib</a> [Bredin2013a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2013a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2013a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsePoignant2013_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Poignant2013']);">
        Towards a Better Integration of Written Names for Unsupervised Speakers Identification in Videos
        </a>
    </div>
    <div id="collapsePoignant2013_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Johann Poignant, Hervé Bredin, Laurent Besacier, Georges Quénot, Claude Barras
<p><em>SLAM 2013, First Workshop on Speech, Language and Audio for Multimedia</em></p>
<blockquote><p>Existing methods for unsupervised identification of speakers in TV broadcast usually rely on the output of a speaker diarization module and try to name each cluster using names provided by another source of information: we call it ``late naming''. Hence, written names extracted from title blocks tend to lead to high precision identification, although they cannot correct errors made during the clustering step. In this paper, we extend our previous ``late naming'' approach in two ways: ``integrated naming'' and ``early naming''. While ``late naming'' relies on a speaker diarization module optimized for speaker diarization, ``integrated naming'' jointly optimize speaker diarization and name propagation in terms of identification errors. ``Early naming'' modifies the speaker diarization module by adding constraints preventing two clusters with different written names to be merged together. While ``integrated naming'' yields similar identification performance as ``late naming'' (with better precision), ``early naming'' improves over this baseline both in terms of identification error rate and stability of the clustering stopping criterion.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Poignant2013']);">.bib</a> [Poignant2013] | <i class="icon-book"></i> <a href="/download/pdfs/Poignant2013.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Poignant2013']);">.pdf</a>        </div>
    </div>
</div>
<h3>2012</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseDelezoide2012_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Delezoide2012']);">
        IRIM at TRECVID 2011: Semantic Indexing and Instance Search
        </a>
    </div>
    <div id="collapseDelezoide2012_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Bertrand Delezoide, Frédéric Precioso, Philippe Gosselin, Miriam Redi, Bernard Mérialdo, Lionel Granjon, Denis Pellerin, Michèle Rombaut, Hervé Jégou, Rémi Vieux, Boris Mansencal, Jenny Benois-Pineau, Stéphane Ayache, Bahjat Safadi, Franck Thollard, Georges Quénot, Hervé Bredin, Matthieu Cord, Alexandre Benoit, Patrick Lambert, Tiberius Strat, Joseph Razik, Sébastion Paris, Hervé Glotin
<p><em>TRECVid 2011, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes its participation to the TRECVID 2011 semantic indexing and instance search tasks. For the semantic indexing task, our approach uses a six-stages processing pipelines for computing scores for the likelihood of a video shot to contain a target concept. These scores are then used for producing a ranked list of images or shots that are the most likely to contain the target concept. The pipeline is composed of the following steps: descriptor extraction, descriptor optimization, classification, fusion of descriptor variants, higher-level fusion, and re-ranking. We evaluated a number of different descriptors and tried different fusion strategies. The best IRIM run has a Mean Inferred Average Precision of 0.1387, which ranked us 5th out of 19 participants. For the instance search task, we we used both object based query and frame based query. We formulated the query in standard way as comparison of visual signatures either of object with parts of DB frames or as a comparison of visual signatures of query and DB frames. To produce visual signatures we also used two apporaches: the first one is the baseline Bag-Of-Visual-Words (BOVW) model based on SURF interest point descriptor; the second approach is a Bag-Of-Regions (BOR) model that extends the traditional notion of BOVW vocabulary not only to keypoint-based descriptors but to region based descriptors.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Delezoide2012']);">.bib</a> [Delezoide2012] | <i class="icon-book"></i> <a href="/download/pdfs/Delezoide2012.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Delezoide2012']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2012_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2012']);">
        Segmentation of TV Shows into Scenes using Speaker Diarization and Speech Recognition
        </a>
    </div>
    <div id="collapseBredin2012_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<blockquote><p>We investigate the use of speaker diarization (SD) and automatic speech recognition (ASR) for the segmentation of audiovisual documents into scenes. We introduce multiple monomodal and multimodal approaches based on a state-of-the-art algorithm called generalized scene transition graph (GSTG). First, we extend the latter with the use of semantic information derived from both SD and ASR. Then, multimodal fusion of color histograms, SD and ASR is investigated at various point of the GSTG pipeline (early, late or intermediate fusion). Experiments driven on a few episodes of a popular TV show indicate that SD and ASR can be successfully combined with visual information and bring an additional +11% relative increase in terms of F-Measure for scene boundary detection over the state-of-the-art baseline.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2012']);">.bib</a> [Bredin2012] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2012.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2012']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2012a_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2012a']);">
        Community-driven Hierarchical Fusion of Numerous Classifiers: Application to Video Semantic Indexing
        </a>
    </div>
    <div id="collapseBredin2012a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<blockquote><p>We deal with the issue of combining dozens of classifiers into a better one. Our first contribution is the introduction of the notion of communities of classifiers. We build a complete graph with one node per classifier and edges weighted by a measure of similarity between connected classifiers. The resulting community structure is uncovered from this graph using the state-of-the-art Louvain algorithm. Our second contribution is a hierarchical fusion approach driven by these communities. First, intra-community fusion results in one classifier per community. Then, inter-community fusion takes advantage of their complementarity to achieve much better classification performance. Application to the combination of 90 classifiers in the framework of TRECVid 2010 Semantic Indexing task shows a 30% increase in performance relative to a baseline flat fusion.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2012a']);">.bib</a> [Bredin2012a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2012a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2012a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseErcolessi2012_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ercolessi2012']);">
        Toward Plot De-Interlacing in TV Series using Scenes Clustering
        </a>
    </div>
    <div id="collapseErcolessi2012_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Hervé Bredin
<p><em>CBMI 2012, 10th Workshop on Content-Based Multimedia Indexing</em></p>
<blockquote><p>Multiple sub-stories usually coexist in every episode of a TV series. We propose several variants of an approach for plot de-interlacing based on scenes clustering -- with the ultimate goal of providing the end-user with tools for fast and easy overview of one episode, one season or the whole TV series. Each scene can be described in three different ways (based on color histograms, speaker diarization or automatic speech recognition outputs) and four clustering approaches are investigated, one of them based on a graphical representation of the video. Experiments are performed on two TV series of different lengths and formats. We show that semantic descriptors (such as speaker diarization) give the best results and underline that our approach provides useful information for plot de-interlacing.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ercolessi2012']);">.bib</a> [Ercolessi2012] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ercolessi2012']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsePoignant2012_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Poignant2012']);">
        Unsupervised Speaker Identification using Overlaid Texts in TV Broadcast
        </a>
    </div>
    <div id="collapsePoignant2012_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Johann Poignant, Hervé Bredin, Viet-Bac Le, Laurent Besacier, Claude Barras, Georges Quénot
<p><em>Interspeech 2012, 13th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>We propose an approach for unsupervised speaker identification in TV broadcast videos, by combining acoustic speaker diarization with person names obtained via video OCR from overlaid texts. Three methods for the propagation of the overlaid names to the speech turns are compared, taking into account the co-occurence duration between the speaker clusters and the names provided by the video OCR and using a task-adapted variant of the TF-IDF information retrieval coefficient. These methods were tested on the REPERE dry-run evaluation corpus, containing 3 hours of annotated videos. Our best unsupervised system reaches a F-measure of 70.2\% when considering all the speakers, and 81.7\% if anchor speakers are left out. By comparison, a mono-modal, supervised speaker identification system with 535 speaker models trained on matching development data and additional TV and radio data only provided a 57.5\% F-measure when considering all the speakers and 45.7\% without anchor.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Poignant2012']);">.bib</a> [Poignant2012] | <i class="icon-book"></i> <a href="/download/pdfs/Poignant2012.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Poignant2012']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2012b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2012b']);">
        Fusion of Speech, Faces and Text for Person Identification in TV Broadcast
        </a>
    </div>
    <div id="collapseBredin2012b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Johann Poignant, Makarand Tapaswi, Guillaume Fortier, Viet Bac Le, Thibault Napoleon, Hua Gao, Claude Barras, Sophie Rosset, Laurent Besacier, Jakob Verbeek, Georges Quénot, Frédéric Jurie, Hazim Kemal Ekenel
<p><em>ECCV 2012, Workshop on Information Fusion in Computer Vision for Concept Recognition</em></p>
<blockquote><p>The REPERE challenge is a project aiming at the evaluation of systems for supervised and unsupervised multimodal recognition of people in TV broadcast. In this paper, we describe, evaluate and discuss QCompere consortium submissions to the 2012 \repere evaluation campaign dry-run. Speaker identification (and face recognition) can be greatly improved when combined with name detection through video optical character recognition. Moreover, we show that unsupervised multimodal person recognition systems can achieve performance nearly as good as supervised monomodal ones (with several hundreds of identity models).</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2012b']);">.bib</a> [Bredin2012b] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2012b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2012b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseStrat2012_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Strat2012']);">
        Hierarchical Late Fusion for Concept Detection in Videos
        </a>
    </div>
    <div id="collapseStrat2012_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Tiberius Strat, Alexandre Benoit, Hervé Bredin, Georges  Quénot, Patrick  Lambert
<p><em>ECCV 2012, Workshop on Information Fusion in Computer Vision for Concept Recognition</em></p>
<blockquote><p>We deal with the issue of combining dozens of classifiers into a better one, for concept detection in videos. We compare three fusion approaches that share a common structure: they all start with a classifier clustering stage, continue with an intra-cluster fusion and end with an inter-cluster fusion. The main difference between them comes from the first stage. The first approach relies on a priori knowledge about the internals of each classifier (low-level descriptors and classification algorithm) to group the set of available classifiers by similarity. The second and third approaches obtain classifier similarity measures directly from their output and group them using agglomerative clustering for the second approach and community detection for the third one.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Strat2012']);">.bib</a> [Strat2012] | <i class="icon-book"></i> <a href="/download/pdfs/Strat2012.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Strat2012']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseErcolessi2012b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ercolessi2012b']);">
        Hierarchical Framework for Plot De-interlacing of TV Series based on Speakers, Dialogues and Images
        </a>
    </div>
    <div id="collapseErcolessi2012b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Sandrine Mouysset, Hervé Bredin
<p><em>AMVA 2012, 1st ACM International Workshop on Audio and Multimedia Methods for Large-Scale Video Analysis at ACM Multimedia 2012</em></p>
<blockquote><p>Since the 90s, TV series tend to introduce more and more main characters and they are often composed of multiple intertwined stories. In this paper, we propose a hierarchical framework of plot de-interlacing  which permits to cluster semantic scenes into stories: a story is a group of scenes not necessarily contiguous but showing a strong semantic relation. Each scene is described using three different modalities (based on color histograms, speaker diarization or automatic speech recognition outputs) as well as their multimodal combination. We introduce the notion of character-driven episodes as episodes where stories are emphasized by the presence or absence of characters, and we propose an automatic method, based on a social graph, to detect these episodes. Depending on whether an episode is character-driven or not, the plot-de-interlacing -which is a scene clustering- is made either through a  traditional average-link agglomerative clustering with speaker modality only, either through a  spectral clustering with the fusion of all modalities. Experiments, conducted on twenty three episodes from three quite different TV series (different lengths and formats), show that the hierarchical framework brings an improvement for all the series.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ercolessi2012b']);">.bib</a> [Ercolessi2012b] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ercolessi2012b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseErcolessi2012c_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ercolessi2012c']);">
        StoViz: Story Visualization of TV Series
        </a>
    </div>
    <div id="collapseErcolessi2012c_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Hervé Bredin, Christine Sénac
<p><em>ACM MM 2012, 20th ACM International Conference on Multimedia</em></p>
<blockquote><p>Recent TV series tend to have more and more complex plot. They follow the lives of numerous characters and are made of multiple intertwined stories. In this paper, we introduce StoViz, a web-based interface allowing a fast overview of this kind of episode structure, based on our plot de-interlacing system. StoViz has two main goals. First, it provides the user with a useful overview of the episode by displaying each story separately and a short abstract extracted from them. Then, it allows an efficient visual comparison of the output of any automatic plot de-interlacing algorithm with the manual annotation in terms of stories and is therefore very helpful for evaluation purposes. StoViz is available online at http://stoviz.niderb.fr.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ercolessi2012c']);">.bib</a> [Ercolessi2012c] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012c.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ercolessi2012c']);">.pdf</a>        </div>
    </div>
</div>
<h3>2011</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseGorisse2011_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Gorisse2011']);">
        IRIM at TRECVID 2010: Semantic Indexing and Instance Search
        </a>
    </div>
    <div id="collapseGorisse2011_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        David Gorisse, Frédéric Precioso, Philippe Gosselin, Lionel Granjon, Denis Pellerin, Michèle Rombaut, Hervé Bredin, Lionel Koenig, Rémi Vieux, Boris Mansencal, Jenny Benois-Pineau, Hugo Boujut, Claire Morand, Hervé Jégou, Stéphane Ayache, Bahjat Safadi, Yubing Tong, Franck Thollard, Georges Quénot, Matthieu Cord, Alexandre Beno\^it, Patrick Lambert
<p><em>TRECVid 2010, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes our participation to the TRECVID 2010 semantic indexing and instance search tasks. For the semantic indexing task, we evaluated a number of different descriptors and tried different fusion strategies, in particular hierarchical fusion. The best IRIM run has a Mean Inferred Average Precision of 0.0442, which is above the task median performance. We found that fusion of the classification scores from different classifier types improves the performance and that even with a quite low individual performance, audio descriptors can help. For the instance search task, we used only one of the example images in our queries. The rank is nearly in the middle of the list of participants. The experiment showed that HSV features outperform the concatenation of HSV and Edge histograms or the Wavelet features.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Gorisse2011']);">.bib</a> [Gorisse2011] | <i class="icon-book"></i> <a href="/download/pdfs/Gorisse2011.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Gorisse2011']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseErcolessi2011_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Ercolessi2011']);">
        Segmenting TV Series into Scenes using Speaker Diarization
        </a>
    </div>
    <div id="collapseErcolessi2011_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Hervé Bredin, Christine Sénac, Philippe Joly
<p><em>WIAMIS 2011, 12th International Workshop on Image Analysis for Multimedia Interactive Services</em></p>
<blockquote><p>In this paper, we propose a novel approach to perform scene segmentation of TV series. Using the output of our existing speaker diarization system, any temporal segment of the video can be described as a binary feature vector. A straightforward segmentation algorithm then allows to group similar contiguous speaker segments into scenes. An additional visual-only color-based segmentation is then used to refine the first segmentation. Experiments are performed on a subset of the Ally McBeal TV series and show promising results, obtained with a rule-free and generic method. For comparison purposes, test corpus annotations and description are made available to the community.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Ercolessi2011']);">.bib</a> [Ercolessi2011] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2011.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Ercolessi2011']);">.pdf</a>        </div>
    </div>
</div>
<h3>2010</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseDelezoide2010_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Delezoide2010']);">
        IRIM at TRECVID 2009: High Level Feature Extraction
        </a>
    </div>
    <div id="collapseDelezoide2010_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Delezoide, Bertrand, Le Borgne, Hervé, Moëllic, Pierre-Alain, Gorisse, David, Precioso, Frédéric, Wang, Feng, Merialdo, Bernard, Gosselin, Philippe, Granjon, Lionel, Pellerin, Denis, Rombaut, Michèle, Bredin, Hervé, Koenig, Lionel, Lachambre, Hélène, El Khoury, Elie, Mansencal, Boris, Zhou, Yifan, Benois-Pineau, Jenny, Jégou, Hervé, Ayache, Stéphane, Safadi, Bahjat, Quenot, Georges, Fabrizio, Jonathan, Cord, Matthieu, Glotin, Hervé, Zhao, Zhongqiu, Dumont, Emilie, Augereau, Bertrand
<p><em>TRECVid 2009, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes our participation to the TRECVID 2009 High Level Features detection task. We evaluated a large number of different descriptors (on TRECVID 2008 data) and tried different fusion strategies, in particular hierarchical fusion and genetic fusion. The best IRIM run has a Mean Inferred Average Precision of 0.1220, which is significantly above TRECVID 2009 HLF detection task median performance. We found that fusion of the classification scores from different classifier types improves the performance and that even with a quite low individual performance, audio descriptors can help.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Delezoide2010']);">.bib</a> [Delezoide2010] | <i class="icon-book"></i> <a href="/download/pdfs/Delezoide2010.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Delezoide2010']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2010_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2010']);">
        IRIT at TRECVID HLF 2009: Audio to the Rescue
        </a>
    </div>
    <div id="collapseBredin2010_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Lionel Koenig, Hélène Lachambre, Elie El Khoury
<p><em>TRECVid 2009, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2010']);">.bib</a> [Bredin2010] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2010.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2010']);">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseCooray2009_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Cooray2009']);">
        An Interactive and Multi-Level Framework for Summarising User-Generated Videos
        </a>
    </div>
    <div id="collapseCooray2009_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Saman H. Cooray, Hervé Bredin, Li-Qun Xu, Noel E. O'Connor
<p><em>ACM MM 2009, 17th ACM International Conference on Multimedia</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Cooray2009']);">.bib</a> [Cooray2009] | <i class="icon-book"></i> <a href="/download/pdfs/Cooray2009.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Cooray2009']);">.pdf</a>        </div>
    </div>
</div>
<h3>2008</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2008_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2008']);">
        Making Talking-Face Authentication Robust to Deliberate Imposture
        </a>
    </div>
    <div id="collapseBredin2008_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>ICASSP 2008, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2008']);">.bib</a> [Bredin2008] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2008.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2008']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseFauve2008_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Fauve2008']);">
        Some Results from the BioSecure Talking-Face Evaluation Campaign
        </a>
    </div>
    <div id="collapseFauve2008_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Benoït Fauve, Hervé Bredin, Walid Karam, Florian Verdet, Aurélien Mayoue, Gérard Chollet, Jean Hennebert, R. Lewis, John Mason, Chafic Mokbel, Dijana Petrovska
<p><em>ICASSP 2008, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Fauve2008']);">.bib</a> [Fauve2008] | <i class="icon-book"></i> <a href="/download/pdfs/Fauve2008.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Fauve2008']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseDumont2008_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Dumont2008']);">
        Rushes Video Summarization using a Collaborative Approach
        </a>
    </div>
    <div id="collapseDumont2008_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Emilie Dumont, Bernard Merialdo, Slim Essid, Werner Bailer, Herwig Rehatschek, Daragh Byrne, Hervé Bredin, Noel O'Connor, Gareth JF Jones, Alan F Smeaton, Martin Haller, Andreas Krutz, Thomas Sikora, Tomas Piatrik
<p><em>TRECVID 2008, ACM International Conference on Multimedia Information Retrieval</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Dumont2008']);">.bib</a> [Dumont2008] | <i class="icon-book"></i> <a href="/download/pdfs/Dumont2008.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Dumont2008']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2008a_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2008a']);">
        Dublin City University at TRECVid 2008 BBC Rushes Summarisation Task
        </a>
    </div>
    <div id="collapseBredin2008a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Daragh Byrne, Hyowon Lee, Noel O'Connor, Gareth JF Jones
<p><em>TRECVID 2008, ACM International Conference on Multimedia Information Retrieval 2008</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2008a']);">.bib</a> [Bredin2008a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2008a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2008a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseDumont2008a_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Dumont2008a']);">
        A Collaborative Approach to Video Summarization
        </a>
    </div>
    <div id="collapseDumont2008a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Emilie Dumont, Bernard Merialdo, Slim Essid, Werner Bailer, Daragh Byrne, Hervé Bredin, Noel O'Connor, Gareth JF Jones, Martin Haller, Andreas Krutz, Thomas Sikora, Tomas Piatrik
<p><em>SAMT 2008, 3rd International Conference on Semantic and Digital Media Technologies</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Dumont2008a']);">.bib</a> [Dumont2008a] | <i class="icon-book"></i> <a href="/download/pdfs/Dumont2008a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Dumont2008a']);">.pdf</a>        </div>
    </div>
</div>
<h3>2007</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2007a_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2007a']);">
        Audio-Visual Speech Synchrony Measure for Talking-Face Identity Verification
        </a>
    </div>
    <div id="collapseBredin2007a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>ICASSP 2007, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2007a']);">.bib</a> [Bredin2007a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2007a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2007a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLandais2007_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Landais2007']);">
        Vérification Audiovisuelle de l'Identité
        </a>
    </div>
    <div id="collapseLandais2007_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Rémi Landais, Hervé Bredin, Leila Zouari, Gérard Chollet
<p><em>Traitement et Analyse de l'Information : Méthodes et Applications</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Landais2007']);">.bib</a> [Landais2007] | <i class="icon-book"></i> <a href="/download/pdfs/Landais2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Landais2007']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseArgones-Rua2007_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Argones-Rua2007']);">
        Aliveness Detection using Coupled Hidden Markov Models
        </a>
    </div>
    <div id="collapseArgones-Rua2007_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Enrique Argones-Rúa, Carmen García-Mateo, Hervé Bredin, Gérard Chollet
<p><em>1st Spanish Workshop on Biometrics</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Argones-Rua2007']);">.bib</a> [Argones-Rua2007] | <i class="icon-book"></i> <a href="/download/pdfs/Argones-Rua2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Argones-Rua2007']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsePerrot2007_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Perrot2007']);">
        Biometrics and Forensic Sciences: the Same Quest for Identification?
        </a>
    </div>
    <div id="collapsePerrot2007_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Patrick Perrot, Hervé Bredin, Gérard Chollet
<p><em>2007 International Crime Science Conference</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Perrot2007']);">.bib</a> [Perrot2007] | <i class="icon-book"></i> <a href="/download/pdfs/Perrot2007.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Perrot2007']);">.pdf</a>        </div>
    </div>
</div>
<h3>2006</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2006_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2006']);">
        Detecting Replay Attacks in Audiovisual Identity Verification
        </a>
    </div>
    <div id="collapseBredin2006_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Antonio Miguel, Ian Witten, Gérard Chollet
<p><em>ICASSP 2006, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2006']);">.bib</a> [Bredin2006] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2006']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseKoreman2006_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Koreman2006']);">
        Multi-Modal Biometric Authentication on the SecurePhone PDA
        </a>
    </div>
    <div id="collapseKoreman2006_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Jacques Koreman, Andrew C Morris, D. Wu, Sabah Jassim, Harin Sellahewa, J. Ehlers, Gérard Chollet, Guido Aversano, Hervé Bredin, Sonia Garcia-Salicetti, Lorène Allano, Bao Ly Van, Bernadette Dorizzi
<p><em>MMUA 2006, Workshop on Multimodal User Authentication</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Koreman2006']);">.bib</a> [Koreman2006] | <i class="icon-book"></i> <a href="/download/pdfs/Koreman2006.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Koreman2006']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2006a_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2006a']);">
        The BioSecure Talking-Face Reference System
        </a>
    </div>
    <div id="collapseBredin2006a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Guido Aversano, Chafic Mokbel, Gérard Chollet
<p><em>MMUA 2006, Workshop on Multimodal User Authentication</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2006a']);">.bib</a> [Bredin2006a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006a.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2006a']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBrugger2006_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Brugger2006']);">
        Reconnaissance Audiovisuelle de la Parole par VMike
        </a>
    </div>
    <div id="collapseBrugger2006_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Fabian Brugger, Leila Zouari, Hervé Bredin, Asma Amehraye, Gérard Chollet, Dominique Pastor, Yang Ni
<p><em>JEP 2006, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Brugger2006']);">.bib</a> [Brugger2006] | <i class="icon-book"></i> <a href="/download/pdfs/Brugger2006.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Brugger2006']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2006b_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2006b']);">
        GMM-based SVM for Face Recognition
        </a>
    </div>
    <div id="collapseBredin2006b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Najim Dehak, Gérard Chollet
<p><em>ICPR 2006, IAPR International Conference on Pattern Recognition</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2006b']);">.bib</a> [Bredin2006b] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006b.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2006b']);">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2006c_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'Bredin2006c']);">
        Measuring Audio and Visual Speech Synchrony: Methods and Applications
        </a>
    </div>
    <div id="collapseBredin2006c_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>VIE 2006, IEE International Conference on Visual Information Engineering</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'Bredin2006c']);">.bib</a> [Bredin2006c] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006c.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'Bredin2006c']);">.pdf</a>        </div>
    </div>
</div>
<h3>2005</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseMcTait2005_Conferenceandworkshopproceedings" onClick="_gaq.push(['_trackEvent', 'Publications', 'Abstract', 'McTait2005']);">
        Adapting a High Quality Audiovisual Database to PDA Quality
        </a>
    </div>
    <div id="collapseMcTait2005_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Kevin McTait, Hervé Bredin, Silvia Colón, Thomas Fillon, Gérard Chollet
<p><em>ISISPA 2005, International Symposium on Image and Signal Processing and Analysis</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib" onClick="_gaq.push(['_trackEvent', 'Publications', 'Bibtex', 'McTait2005']);">.bib</a> [McTait2005] | <i class="icon-book"></i> <a href="/download/pdfs/McTait2005.pdf" onClick="_gaq.push(['_trackEvent', 'Publications', 'Download', 'McTait2005']);">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
</div>
