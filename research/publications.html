---
layout: page
title: "Publications"
description: ""
tagline: "last updated on July 26, 2012"
group: research
---
{% include JB/setup %}
<ul class="nav nav-tabs">
<li><a href="#All" data-toggle="tab">All (37)</a></li>
<li><a href="#Journalarticles" data-toggle="tab">Journal articles (5)</a></li>
<li><a href="#Bookchapters" data-toggle="tab">Book chapters (3)</a></li>
<li><a href="#Conferenceandworkshopproceedings" data-toggle="tab">Conference and workshop proceedings (28)</a></li>
</ul>
<div id="myTabContent" class="tab-content">
<div class="tab-pane fade in active" id="All">
<div class="accordion" id="accordionAll">
<h3>2012</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2012a_All">
        Community-driven Hierarchical Fusion of Numerous Classifiers: Application to Video Semantic Indexing
        </a>
    </div>
    <div id="collapseBredin2012a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<blockquote><p>We deal with the issue of combining dozens of classifiers into a better one. Our first contribution is the introduction of the notion of communities of classifiers. We build a complete graph with one node per classifier and edges weighted by a measure of similarity between connected classifiers. The resulting community structure is uncovered from this graph using the state-of-the-art Louvain algorithm. Our second contribution is a hierarchical fusion approach driven by these communities. First, intra-community fusion results in one classifier per community. Then, inter-community fusion takes advantage of their complementarity to achieve much better classification performance. Application to the combination of 90 classifiers in the framework of TRECVid 2010 Semantic Indexing task shows a 30% increase in performance relative to a baseline flat fusion.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2012a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2012a.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2012_All">
        Segmentation of TV Shows into Scenes using Speaker Diarization and Speech Recognition
        </a>
    </div>
    <div id="collapseBredin2012_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<blockquote><p>We investigate the use of speaker diarization (SD) and automatic speech recognition (ASR) for the segmentation of audiovisual documents into scenes. We introduce multiple monomodal and multimodal approaches based on a state-of-the-art algorithm called generalized scene transition graph (GSTG). First, we extend the latter with the use of semantic information derived from both SD and ASR. Then, multimodal fusion of color histograms, SD and ASR is investigated at various point of the GSTG pipeline (early, late or intermediate fusion). Experiments driven on a few episodes of a popular TV show indicate that SD and ASR can be successfully combined with visual information and bring an additional +11% relative increase in terms of F-Measure for scene boundary detection over the state-of-the-art baseline.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2012] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2012.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseErcolessi2012_All">
        Toward Plot De-Interlacing in TV Series using Scenes Clustering
        </a>
    </div>
    <div id="collapseErcolessi2012_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Hervé Bredin
<p><em>CBMI 2012, 10th Workshop on Content-Based Multimedia Indexing</em></p>
<blockquote><p>Multiple sub-stories usually coexist in every episode of a TV series. We propose several variants of an approach for plot de-interlacing based on scenes clustering -- with the ultimate goal of providing the end-user with tools for fast and easy overview of one episode, one season or the whole TV series. Each scene can be described in three different ways (based on color histograms, speaker diarization or automatic speech recognition outputs) and four clustering approaches are investigated, one of them based on a graphical representation of the video. Experiments are performed on two TV series of different lengths and formats. We show that semantic descriptors (such as speaker diarization) give the best results and underline that our approach provides useful information for plot de-interlacing.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ercolessi2012] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsePoignant2012_All">
        Unsupervised Speaker Identification using Overlaid Texts in TV Broadcast
        </a>
    </div>
    <div id="collapsePoignant2012_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Johann Poignant, Hervé Bredin, Viet-Bac Le, Laurent Besacier, Claude Barras, Georges Quénot
<p><em>Interspeech 2012, 13th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>We propose an approach for unsupervised speaker identification in TV broadcast videos, by combining acoustic speaker diarization with person names obtained via video OCR from overlaid texts. Three methods for the propagation of the overlaid names to the speech turns are compared, taking into account the co-occurence duration between the speaker clusters and the names provided by the video OCR and using a task-adapted variant of the TF-IDF information retrieval coefficient. These methods were tested on the REPERE dry-run evaluation corpus, containing 3 hours of annotated videos. Our best unsupervised system reaches a F-measure of 70.2\% when considering all the speakers, and 81.7\% if anchor speakers are left out. By comparison, a mono-modal, supervised speaker identification system with 535 speaker models trained on matching development data and additional TV and radio data only provided a 57.5\% F-measure when considering all the speakers and 45.7\% without anchor.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Poignant2012] | <i class="icon-book"></i> <a href="/download/pdfs/Poignant2012.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseErcolessi2012a_All">
        Vers un Résumé Automatique de Séries Télévisées basé sur une Recherche Multimodale d'Histoires
        </a>
    </div>
    <div id="collapseErcolessi2012a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Hervé Bredin, Sandrine Mouysset
<p><em>Document Numérique -- Numéro Spécial ``Résumé Automatique des Documents''</em></p>
<blockquote><p>Modern TV series have complex plots made of several intertwined stories following numerous characters. In this paper, we propose an approach for automatically detecting these stories in order to generate video summaries and we propose a visualization tool to have a quick and easy look at TV series. Based on automatic scene segmentation of each TV series episode (a scene is defined as temporally and spatially continuous and semantically coherent), scenes are clustered into stories, made of (non necessarily adjacent) semantically similar scenes. Visual, audio and text modalities are combined to achieve better scene segmentation and story detection performance. An extraction of salient scenes from stories is performed to create the summary. Experimentations are conducted on two TV series with different formats.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ercolessi2012a] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012a.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseDelezoide2012_All">
        IRIM at TRECVID 2011: Semantic Indexing and Instance Search
        </a>
    </div>
    <div id="collapseDelezoide2012_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Bertrand Delezoide, Frédéric Precioso, Philippe Gosselin, Miriam Redi, Bernard Mérialdo, Lionel Granjon, Denis Pellerin, Michèle Rombaut, Hervé Jégou, Rémi Vieux, Boris Mansencal, Jenny Benois-Pineau, Stéphane Ayache, Bahjat Safadi, Franck Thollard, Georges Quénot, Hervé Bredin, Matthieu Cord, Alexandre Benoit, Patrick Lambert, Tiberius Strat, Joseph Razik, Sébastion Paris, Hervé Glotin
<p><em>TRECVid 2011, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes its participation to the TRECVID 2011 semantic indexing and instance search tasks. For the semantic indexing task, our approach uses a six-stages processing pipelines for computing scores for the likelihood of a video shot to contain a target concept. These scores are then used for producing a ranked list of images or shots that are the most likely to contain the target concept. The pipeline is composed of the following steps: descriptor extraction, descriptor optimization, classification, fusion of descriptor variants, higher-level fusion, and re-ranking. We evaluated a number of different descriptors and tried different fusion strategies. The best IRIM run has a Mean Inferred Average Precision of 0.1387, which ranked us 5th out of 19 participants. For the instance search task, we we used both object based query and frame based query. We formulated the query in standard way as comparison of visual signatures either of object with parts of DB frames or as a comparison of visual signatures of query and DB frames. To produce visual signatures we also used two apporaches: the first one is the baseline Bag-Of-Visual-Words (BOVW) model based on SURF interest point descriptor; the second approach is a Bag-Of-Regions (BOR) model that extends the traditional notion of BOVW vocabulary not only to keypoint-based descriptors but to region based descriptors.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Delezoide2012] | <i class="icon-book"></i> <a href="/download/pdfs/Delezoide2012.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseErcolessi2012b_All">
        Scene Clustering for TV Series Plot De-Interlacing based on Speakers, Dialogues and Images
        </a>
    </div>
    <div id="collapseErcolessi2012b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Sandrine Mouysset, Hervé Bredin
<p><em>AMVA 2012, 1st ACM International Workshop on Audio and Multimedia Methods for Large-Scale Video Analysis at ACM Multimedia 2012</em></p>
<blockquote><p>Recent TV series tend to have more and more complex plot. They follow the lives of numerous characters and are made of multiple intertwined stories. In this paper, we propose a hierarchical framework of plot de-interlacing  which permits to cluster semantic scenes into stories: a story is a group of scenes not necessarily contiguous but showing a strong semantic relation. Each scene is described using three different modalities (based on color histograms, speaker diarization or automatic speech recognition outputs) as well as their multimodal combination. We introduce the notion of character-driven episodes as episodes where stories are emphasized by the presence or absence of characters, and we propose an automatic method, based on a social graph, to detect these episodes. Depending on whether an episode is character-driven or not, the plot-de-interlacing -- which is a scene clustering -- is made either through a traditional average-link agglomerative clustering with speaker modality only, either through a  spectral clustering with the fusion of all modalities. Experiments, conducted on twenty three episodes from three quite different TV series (different lengths and formats), show that the hierarchical framework brings an improvement for all the series.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ercolessi2012b] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012b.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseErcolessi2012c_All">
        StoViz: Story Visualization of TV Series
        </a>
    </div>
    <div id="collapseErcolessi2012c_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Hervé Bredin, Christine Sénac
<p><em>ACM MM 2012, 20th ACM International Conference on Multimedia</em></p>
<blockquote><p>Recent TV series tend to have more and more complex plot. They follow the lives of numerous characters and are made of multiple intertwined stories. In this paper, we introduce StoViz, a web-based interface allowing a fast overview of this kind of episode structure, based on our plot de-interlacing system. StoViz has two main goals. First, it provides the user with a useful overview of the episode by displaying each story separately and a short abstract extracted from them. Then, it allows an efficient visual comparison of the output of any automatic plot de-interlacing algorithm with the manual annotation in terms of stories and is therefore very helpful for evaluation purposes. StoViz is available online at http://stoviz.niderb.fr.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ercolessi2012c] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012c.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2011</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseErcolessi2011_All">
        Segmenting TV Series into Scenes using Speaker Diarization
        </a>
    </div>
    <div id="collapseErcolessi2011_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Hervé Bredin, Christine Sénac, Philippe Joly
<p><em>WIAMIS 2011, 12th International Workshop on Image Analysis for Multimedia Interactive Services</em></p>
<blockquote><p>In this paper, we propose a novel approach to perform scene segmentation of TV series. Using the output of our existing speaker diarization system, any temporal segment of the video can be described as a binary feature vector. A straightforward segmentation algorithm then allows to group similar contiguous speaker segments into scenes. An additional visual-only color-based segmentation is then used to refine the first segmentation. Experiments are performed on a subset of the Ally McBeal TV series and show promising results, obtained with a rule-free and generic method. For comparison purposes, test corpus annotations and description are made available to the community.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ercolessi2011] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2011.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseRamona2011_All">
        A Public Audio Identification Evaluation Framework for Broadcast Monitoring
        </a>
    </div>
    <div id="collapseRamona2011_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Mathieu Ramona, Sébastien Fenet, Raphaël Blouet, Hervé Bredin, Thomas Fillon, Geoffroy Peeters
<p><em>Applied Artificial Intelligence</em></p>
<blockquote><p>This paper presents the first public framework for the evaluation of audio fingerprinting techniques. Although the domain of audio identification is very active, both in the industry and the academic world, there is nowadays no common basis to compare the proposed techniques. This is because corpuses and evaluation protocols differ between the authors. The framework we present here corresponds to a use-case in which audio excerpts have to be detected in a radio broadcast stream. This scenario indeed naturally provides a large variety of audio distortions that makes this task a real challenge for fingerprinting systems. Scoring metrics are discussed, with regard to this particular scenario. We then describe a whole evaluation framework including an audio corpus, along with the related groundtruth annotation, and a toolkit for the computation of the score metrics. An example of application of this framework is finally detailed. This took place during the evaluation campaign of the Quaero project. This evaluation framework is publicly available for download and constitutes a simple, yet thorough, platform that can be used by the community in the field of audio identification, to encourage reproducible results.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ramona2011] | <i class="icon-book"></i> <a href="/download/pdfs/Ramona2011.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseGorisse2011_All">
        IRIM at TRECVID 2010: Semantic Indexing and Instance Search
        </a>
    </div>
    <div id="collapseGorisse2011_All" class="accordion-body collapse">
        <div class="accordion-inner">
        David Gorisse, Frédéric Precioso, Philippe Gosselin, Lionel Granjon, Denis Pellerin, Michèle Rombaut, Hervé Bredin, Lionel Koenig, Rémi Vieux, Boris Mansencal, Jenny Benois-Pineau, Hugo Boujut, Claire Morand, Hervé Jégou, Stéphane Ayache, Bahjat Safadi, Yubing Tong, Franck Thollard, Georges Quénot, Matthieu Cord, Alexandre Beno\^it, Patrick Lambert
<p><em>TRECVid 2010, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes our participation to the TRECVID 2010 semantic indexing and instance search tasks. For the semantic indexing task, we evaluated a number of different descriptors and tried different fusion strategies, in particular hierarchical fusion. The best IRIM run has a Mean Inferred Average Precision of 0.0442, which is above the task median performance. We found that fusion of the classification scores from different classifier types improves the performance and that even with a quite low individual performance, audio descriptors can help. For the instance search task, we used only one of the example images in our queries. The rank is nearly in the middle of the list of participants. The experiment showed that HSV features outperform the concatenation of HSV and Edge histograms or the Wavelet features.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Gorisse2011] | <i class="icon-book"></i> <a href="/download/pdfs/Gorisse2011.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2010</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2010_All">
        IRIT at TRECVID HLF 2009: Audio to the Rescue
        </a>
    </div>
    <div id="collapseBredin2010_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Lionel Koenig, Hélène Lachambre, Elie El Khoury
<p><em>TRECVid 2009, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2010] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2010.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseDelezoide2010_All">
        IRIM at TRECVID 2009: High Level Feature Extraction
        </a>
    </div>
    <div id="collapseDelezoide2010_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Delezoide, Bertrand, Le Borgne, Hervé, Moëllic, Pierre-Alain, Gorisse, David, Precioso, Frédéric, Wang, Feng, Merialdo, Bernard, Gosselin, Philippe, Granjon, Lionel, Pellerin, Denis, Rombaut, Michèle, Bredin, Hervé, Koenig, Lionel, Lachambre, Hélène, El Khoury, Elie, Mansencal, Boris, Zhou, Yifan, Benois-Pineau, Jenny, Jégou, Hervé, Ayache, Stéphane, Safadi, Bahjat, Quenot, Georges, Fabrizio, Jonathan, Cord, Matthieu, Glotin, Hervé, Zhao, Zhongqiu, Dumont, Emilie, Augereau, Bertrand
<p><em>TRECVid 2009, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes our participation to the TRECVID 2009 High Level Features detection task. We evaluated a large number of different descriptors (on TRECVID 2008 data) and tried different fusion strategies, in particular hierarchical fusion and genetic fusion. The best IRIM run has a Mean Inferred Average Precision of 0.1220, which is significantly above TRECVID 2009 HLF detection task median performance. We found that fusion of the classification scores from different classifier types improves the performance and that even with a quite low individual performance, audio descriptors can help.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Delezoide2010] | <i class="icon-book"></i> <a href="/download/pdfs/Delezoide2010.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2009_All">
        Talking-Face Authentication
        </a>
    </div>
    <div id="collapseBredin2009_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Aurélien Mayoue, Gérard Chollet, Bernadette Dorizzi
<p><em>Guide to Biometric Reference Systems and Performance Evaluation</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2009] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2009.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseKaram2009_All">
        Talking-Face Identity Verification, Audiovisual Forgery and Robustness Issues
        </a>
    </div>
    <div id="collapseKaram2009_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Walid Karam, Hervé Bredin, Hanna Greige, Gérard Chollet, Chafic Mokbel
<p><em>EURASIP Journal on Advances in Signal Processing, Special Issue on Recent Advances in Biometric Systems: A Signal Processing Perspective</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Karam2009] | <i class="icon-book"></i> <a href="/download/pdfs/Karam2009.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseCooray2009_All">
        An Interactive and Multi-Level Framework for Summarising User-Generated Videos
        </a>
    </div>
    <div id="collapseCooray2009_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Saman H. Cooray, Hervé Bredin, Li-Qun Xu, Noel E. O'Connor
<p><em>ACM MM 2009, 17th ACM International Conference on Multimedia</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Cooray2009] | <i class="icon-book"></i> <a href="/download/pdfs/Cooray2009.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2008</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseFauve2008_All">
        Some Results from the BioSecure Talking-Face Evaluation Campaign
        </a>
    </div>
    <div id="collapseFauve2008_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Benoït Fauve, Hervé Bredin, Walid Karam, Florian Verdet, Aurélien Mayoue, Gérard Chollet, Jean Hennebert, R. Lewis, John Mason, Chafic Mokbel, Dijana Petrovska
<p><em>ICASSP 2008, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Fauve2008] | <i class="icon-book"></i> <a href="/download/pdfs/Fauve2008.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseDumont2008_All">
        Rushes Video Summarization using a Collaborative Approach
        </a>
    </div>
    <div id="collapseDumont2008_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Emilie Dumont, Bernard Merialdo, Slim Essid, Werner Bailer, Herwig Rehatschek, Daragh Byrne, Hervé Bredin, Noel O'Connor, Gareth JF Jones, Alan F Smeaton, Martin Haller, Andreas Krutz, Thomas Sikora, Tomas Piatrik
<p><em>TRECVID 2008, ACM International Conference on Multimedia Information Retrieval</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Dumont2008] | <i class="icon-book"></i> <a href="/download/pdfs/Dumont2008.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2008_All">
        Making Talking-Face Authentication Robust to Deliberate Imposture
        </a>
    </div>
    <div id="collapseBredin2008_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>ICASSP 2008, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2008] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2008.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2008a_All">
        Dublin City University at TRECVid 2008 BBC Rushes Summarisation Task
        </a>
    </div>
    <div id="collapseBredin2008a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Daragh Byrne, Hyowon Lee, Noel O'Connor, Gareth JF Jones
<p><em>TRECVID 2008, ACM International Conference on Multimedia Information Retrieval 2008</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2008a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2008a.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseDumont2008a_All">
        A Collaborative Approach to Video Summarization
        </a>
    </div>
    <div id="collapseDumont2008a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Emilie Dumont, Bernard Merialdo, Slim Essid, Werner Bailer, Daragh Byrne, Hervé Bredin, Noel O'Connor, Gareth JF Jones, Martin Haller, Andreas Krutz, Thomas Sikora, Tomas Piatrik
<p><em>SAMT 2008, 3rd International Conference on Semantic and Digital Media Technologies</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Dumont2008a] | <i class="icon-book"></i> <a href="/download/pdfs/Dumont2008a.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2007</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2007b_All">
        Vérification de l'Identité d'un Visage Parlant. Apport de la Mesure de Synchronie Audiovisuelle face aux Tentatives Délibérées d'Imposture.
        </a>
    </div>
    <div id="collapseBredin2007b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2007b] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2007b.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseLandais2007_All">
        Vérification Audiovisuelle de l'Identité
        </a>
    </div>
    <div id="collapseLandais2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Rémi Landais, Hervé Bredin, Leila Zouari, Gérard Chollet
<p><em>Traitement et Analyse de l'Information : Méthodes et Applications</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Landais2007] | <i class="icon-book"></i> <a href="/download/pdfs/Landais2007.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseChollet2007_All">
        Some Experiments in Audio-Visual Speech Processing
        </a>
    </div>
    <div id="collapseChollet2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Gérard Chollet, Rémi Landais, Hervé Bredin, Thomas Hueber, Chafic Mokbel, Patrick Perrot, Leila Zouari
<p><em>Non-Linear Speech Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Chollet2007] | <i class="icon-book"></i> <a href="/download/pdfs/Chollet2007.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapsePerrot2007_All">
        Biometrics and Forensic Sciences: the Same Quest for Identification?
        </a>
    </div>
    <div id="collapsePerrot2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Patrick Perrot, Hervé Bredin, Gérard Chollet
<p><em>2007 International Crime Science Conference</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Perrot2007] | <i class="icon-book"></i> <a href="/download/pdfs/Perrot2007.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseAbboud2007_All">
        Audio-Visual Identity Verification: an Introductory Overview
        </a>
    </div>
    <div id="collapseAbboud2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Bouchra Abboud, Hervé Bredin, Guido Aversano, Gérard Chollet
<p><em>Progress in Nonlinear Speech Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Abboud2007] | <i class="icon-book"></i> <a href="/download/pdfs/Abboud2007.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseArgones-Rua2007a_All">
        Audio-Visual Speech Asynchrony Detection using Co-Inertia Analysis and Coupled Hidden Markov Models
        </a>
    </div>
    <div id="collapseArgones-Rua2007a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Enrique Argones-Rúa, Hervé Bredin, Carmen García-Mateo, Gérard Chollet, Daniel González-Jiménez
<p><em>Pattern Analysis and Applications Journal</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Argones-Rua2007a] | <i class="icon-book"></i> <a href="/download/pdfs/Argones-Rua2007a.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2007_All">
        Audio-Visual Speech Synchrony Measure: Application to Biometrics
        </a>
    </div>
    <div id="collapseBredin2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>EURASIP Journal on Advances in Signal Processing, Special Issue on Knowledge-Assisted Media Analysis for Interactive Multimedia Applications</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2007] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2007.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseArgones-Rua2007_All">
        Aliveness Detection using Coupled Hidden Markov Models
        </a>
    </div>
    <div id="collapseArgones-Rua2007_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Enrique Argones-Rúa, Carmen García-Mateo, Hervé Bredin, Gérard Chollet
<p><em>1st Spanish Workshop on Biometrics</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Argones-Rua2007] | <i class="icon-book"></i> <a href="/download/pdfs/Argones-Rua2007.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2007a_All">
        Audio-Visual Speech Synchrony Measure for Talking-Face Identity Verification
        </a>
    </div>
    <div id="collapseBredin2007a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>ICASSP 2007, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2007a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2007a.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2006</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2006a_All">
        The BioSecure Talking-Face Reference System
        </a>
    </div>
    <div id="collapseBredin2006a_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Guido Aversano, Chafic Mokbel, Gérard Chollet
<p><em>MMUA 2006, Workshop on Multimodal User Authentication</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2006a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006a.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBrugger2006_All">
        Reconnaissance Audiovisuelle de la Parole par VMike
        </a>
    </div>
    <div id="collapseBrugger2006_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Fabian Brugger, Leila Zouari, Hervé Bredin, Asma Amehraye, Gérard Chollet, Dominique Pastor, Yang Ni
<p><em>JEP 2006, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Brugger2006] | <i class="icon-book"></i> <a href="/download/pdfs/Brugger2006.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseKoreman2006_All">
        Multi-Modal Biometric Authentication on the SecurePhone PDA
        </a>
    </div>
    <div id="collapseKoreman2006_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Jacques Koreman, Andrew C Morris, D. Wu, Sabah Jassim, Harin Sellahewa, J. Ehlers, Gérard Chollet, Guido Aversano, Hervé Bredin, Sonia Garcia-Salicetti, Lorène Allano, Bao Ly Van, Bernadette Dorizzi
<p><em>MMUA 2006, Workshop on Multimodal User Authentication</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Koreman2006] | <i class="icon-book"></i> <a href="/download/pdfs/Koreman2006.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2006c_All">
        Measuring Audio and Visual Speech Synchrony: Methods and Applications
        </a>
    </div>
    <div id="collapseBredin2006c_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>VIE 2006, IEE International Conference on Visual Information Engineering</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2006c] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006c.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2006b_All">
        GMM-based SVM for Face Recognition
        </a>
    </div>
    <div id="collapseBredin2006b_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Najim Dehak, Gérard Chollet
<p><em>ICPR 2006, IAPR International Conference on Pattern Recognition</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2006b] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006b.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseBredin2006_All">
        Detecting Replay Attacks in Audiovisual Identity Verification
        </a>
    </div>
    <div id="collapseBredin2006_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Antonio Miguel, Ian Witten, Gérard Chollet
<p><em>ICASSP 2006, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2006] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2005</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionAll" href="#collapseMcTait2005_All">
        Adapting a High Quality Audiovisual Database to PDA Quality
        </a>
    </div>
    <div id="collapseMcTait2005_All" class="accordion-body collapse">
        <div class="accordion-inner">
        Kevin McTait, Hervé Bredin, Silvia Colón, Thomas Fillon, Gérard Chollet
<p><em>ISISPA 2005, International Symposium on Image and Signal Processing and Analysis</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [McTait2005] | <i class="icon-book"></i> <a href="/download/pdfs/McTait2005.pdf">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
<div class="tab-pane fade in" id="Journalarticles">
<div class="accordion" id="accordionJournalarticles">
<h3>2012</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseErcolessi2012a_Journalarticles">
        Vers un Résumé Automatique de Séries Télévisées basé sur une Recherche Multimodale d'Histoires
        </a>
    </div>
    <div id="collapseErcolessi2012a_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Hervé Bredin, Sandrine Mouysset
<p><em>Document Numérique -- Numéro Spécial ``Résumé Automatique des Documents''</em></p>
<blockquote><p>Modern TV series have complex plots made of several intertwined stories following numerous characters. In this paper, we propose an approach for automatically detecting these stories in order to generate video summaries and we propose a visualization tool to have a quick and easy look at TV series. Based on automatic scene segmentation of each TV series episode (a scene is defined as temporally and spatially continuous and semantically coherent), scenes are clustered into stories, made of (non necessarily adjacent) semantically similar scenes. Visual, audio and text modalities are combined to achieve better scene segmentation and story detection performance. An extraction of salient scenes from stories is performed to create the summary. Experimentations are conducted on two TV series with different formats.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ercolessi2012a] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012a.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2011</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseRamona2011_Journalarticles">
        A Public Audio Identification Evaluation Framework for Broadcast Monitoring
        </a>
    </div>
    <div id="collapseRamona2011_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Mathieu Ramona, Sébastien Fenet, Raphaël Blouet, Hervé Bredin, Thomas Fillon, Geoffroy Peeters
<p><em>Applied Artificial Intelligence</em></p>
<blockquote><p>This paper presents the first public framework for the evaluation of audio fingerprinting techniques. Although the domain of audio identification is very active, both in the industry and the academic world, there is nowadays no common basis to compare the proposed techniques. This is because corpuses and evaluation protocols differ between the authors. The framework we present here corresponds to a use-case in which audio excerpts have to be detected in a radio broadcast stream. This scenario indeed naturally provides a large variety of audio distortions that makes this task a real challenge for fingerprinting systems. Scoring metrics are discussed, with regard to this particular scenario. We then describe a whole evaluation framework including an audio corpus, along with the related groundtruth annotation, and a toolkit for the computation of the score metrics. An example of application of this framework is finally detailed. This took place during the evaluation campaign of the Quaero project. This evaluation framework is publicly available for download and constitutes a simple, yet thorough, platform that can be used by the community in the field of audio identification, to encourage reproducible results.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ramona2011] | <i class="icon-book"></i> <a href="/download/pdfs/Ramona2011.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseKaram2009_Journalarticles">
        Talking-Face Identity Verification, Audiovisual Forgery and Robustness Issues
        </a>
    </div>
    <div id="collapseKaram2009_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Walid Karam, Hervé Bredin, Hanna Greige, Gérard Chollet, Chafic Mokbel
<p><em>EURASIP Journal on Advances in Signal Processing, Special Issue on Recent Advances in Biometric Systems: A Signal Processing Perspective</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Karam2009] | <i class="icon-book"></i> <a href="/download/pdfs/Karam2009.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2007</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseArgones-Rua2007a_Journalarticles">
        Audio-Visual Speech Asynchrony Detection using Co-Inertia Analysis and Coupled Hidden Markov Models
        </a>
    </div>
    <div id="collapseArgones-Rua2007a_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Enrique Argones-Rúa, Hervé Bredin, Carmen García-Mateo, Gérard Chollet, Daniel González-Jiménez
<p><em>Pattern Analysis and Applications Journal</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Argones-Rua2007a] | <i class="icon-book"></i> <a href="/download/pdfs/Argones-Rua2007a.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionJournalarticles" href="#collapseBredin2007_Journalarticles">
        Audio-Visual Speech Synchrony Measure: Application to Biometrics
        </a>
    </div>
    <div id="collapseBredin2007_Journalarticles" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>EURASIP Journal on Advances in Signal Processing, Special Issue on Knowledge-Assisted Media Analysis for Interactive Multimedia Applications</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2007] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2007.pdf">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
<div class="tab-pane fade in" id="Bookchapters">
<div class="accordion" id="accordionBookchapters">
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionBookchapters" href="#collapseBredin2009_Bookchapters">
        Talking-Face Authentication
        </a>
    </div>
    <div id="collapseBredin2009_Bookchapters" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Aurélien Mayoue, Gérard Chollet, Bernadette Dorizzi
<p><em>Guide to Biometric Reference Systems and Performance Evaluation</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2009] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2009.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2007</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionBookchapters" href="#collapseChollet2007_Bookchapters">
        Some Experiments in Audio-Visual Speech Processing
        </a>
    </div>
    <div id="collapseChollet2007_Bookchapters" class="accordion-body collapse">
        <div class="accordion-inner">
        Gérard Chollet, Rémi Landais, Hervé Bredin, Thomas Hueber, Chafic Mokbel, Patrick Perrot, Leila Zouari
<p><em>Non-Linear Speech Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Chollet2007] | <i class="icon-book"></i> <a href="/download/pdfs/Chollet2007.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionBookchapters" href="#collapseAbboud2007_Bookchapters">
        Audio-Visual Identity Verification: an Introductory Overview
        </a>
    </div>
    <div id="collapseAbboud2007_Bookchapters" class="accordion-body collapse">
        <div class="accordion-inner">
        Bouchra Abboud, Hervé Bredin, Guido Aversano, Gérard Chollet
<p><em>Progress in Nonlinear Speech Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Abboud2007] | <i class="icon-book"></i> <a href="/download/pdfs/Abboud2007.pdf">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
<div class="tab-pane fade in" id="Conferenceandworkshopproceedings">
<div class="accordion" id="accordionConferenceandworkshopproceedings">
<h3>2012</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2012a_Conferenceandworkshopproceedings">
        Community-driven Hierarchical Fusion of Numerous Classifiers: Application to Video Semantic Indexing
        </a>
    </div>
    <div id="collapseBredin2012a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<blockquote><p>We deal with the issue of combining dozens of classifiers into a better one. Our first contribution is the introduction of the notion of communities of classifiers. We build a complete graph with one node per classifier and edges weighted by a measure of similarity between connected classifiers. The resulting community structure is uncovered from this graph using the state-of-the-art Louvain algorithm. Our second contribution is a hierarchical fusion approach driven by these communities. First, intra-community fusion results in one classifier per community. Then, inter-community fusion takes advantage of their complementarity to achieve much better classification performance. Application to the combination of 90 classifiers in the framework of TRECVid 2010 Semantic Indexing task shows a 30% increase in performance relative to a baseline flat fusion.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2012a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2012a.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2012_Conferenceandworkshopproceedings">
        Segmentation of TV Shows into Scenes using Speaker Diarization and Speech Recognition
        </a>
    </div>
    <div id="collapseBredin2012_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin
<p><em>ICASSP 2012, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<blockquote><p>We investigate the use of speaker diarization (SD) and automatic speech recognition (ASR) for the segmentation of audiovisual documents into scenes. We introduce multiple monomodal and multimodal approaches based on a state-of-the-art algorithm called generalized scene transition graph (GSTG). First, we extend the latter with the use of semantic information derived from both SD and ASR. Then, multimodal fusion of color histograms, SD and ASR is investigated at various point of the GSTG pipeline (early, late or intermediate fusion). Experiments driven on a few episodes of a popular TV show indicate that SD and ASR can be successfully combined with visual information and bring an additional +11% relative increase in terms of F-Measure for scene boundary detection over the state-of-the-art baseline.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2012] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2012.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseErcolessi2012_Conferenceandworkshopproceedings">
        Toward Plot De-Interlacing in TV Series using Scenes Clustering
        </a>
    </div>
    <div id="collapseErcolessi2012_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Hervé Bredin
<p><em>CBMI 2012, 10th Workshop on Content-Based Multimedia Indexing</em></p>
<blockquote><p>Multiple sub-stories usually coexist in every episode of a TV series. We propose several variants of an approach for plot de-interlacing based on scenes clustering -- with the ultimate goal of providing the end-user with tools for fast and easy overview of one episode, one season or the whole TV series. Each scene can be described in three different ways (based on color histograms, speaker diarization or automatic speech recognition outputs) and four clustering approaches are investigated, one of them based on a graphical representation of the video. Experiments are performed on two TV series of different lengths and formats. We show that semantic descriptors (such as speaker diarization) give the best results and underline that our approach provides useful information for plot de-interlacing.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ercolessi2012] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsePoignant2012_Conferenceandworkshopproceedings">
        Unsupervised Speaker Identification using Overlaid Texts in TV Broadcast
        </a>
    </div>
    <div id="collapsePoignant2012_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Johann Poignant, Hervé Bredin, Viet-Bac Le, Laurent Besacier, Claude Barras, Georges Quénot
<p><em>Interspeech 2012, 13th Annual Conference of the International Speech Communication Association</em></p>
<blockquote><p>We propose an approach for unsupervised speaker identification in TV broadcast videos, by combining acoustic speaker diarization with person names obtained via video OCR from overlaid texts. Three methods for the propagation of the overlaid names to the speech turns are compared, taking into account the co-occurence duration between the speaker clusters and the names provided by the video OCR and using a task-adapted variant of the TF-IDF information retrieval coefficient. These methods were tested on the REPERE dry-run evaluation corpus, containing 3 hours of annotated videos. Our best unsupervised system reaches a F-measure of 70.2\% when considering all the speakers, and 81.7\% if anchor speakers are left out. By comparison, a mono-modal, supervised speaker identification system with 535 speaker models trained on matching development data and additional TV and radio data only provided a 57.5\% F-measure when considering all the speakers and 45.7\% without anchor.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Poignant2012] | <i class="icon-book"></i> <a href="/download/pdfs/Poignant2012.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseDelezoide2012_Conferenceandworkshopproceedings">
        IRIM at TRECVID 2011: Semantic Indexing and Instance Search
        </a>
    </div>
    <div id="collapseDelezoide2012_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Bertrand Delezoide, Frédéric Precioso, Philippe Gosselin, Miriam Redi, Bernard Mérialdo, Lionel Granjon, Denis Pellerin, Michèle Rombaut, Hervé Jégou, Rémi Vieux, Boris Mansencal, Jenny Benois-Pineau, Stéphane Ayache, Bahjat Safadi, Franck Thollard, Georges Quénot, Hervé Bredin, Matthieu Cord, Alexandre Benoit, Patrick Lambert, Tiberius Strat, Joseph Razik, Sébastion Paris, Hervé Glotin
<p><em>TRECVid 2011, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes its participation to the TRECVID 2011 semantic indexing and instance search tasks. For the semantic indexing task, our approach uses a six-stages processing pipelines for computing scores for the likelihood of a video shot to contain a target concept. These scores are then used for producing a ranked list of images or shots that are the most likely to contain the target concept. The pipeline is composed of the following steps: descriptor extraction, descriptor optimization, classification, fusion of descriptor variants, higher-level fusion, and re-ranking. We evaluated a number of different descriptors and tried different fusion strategies. The best IRIM run has a Mean Inferred Average Precision of 0.1387, which ranked us 5th out of 19 participants. For the instance search task, we we used both object based query and frame based query. We formulated the query in standard way as comparison of visual signatures either of object with parts of DB frames or as a comparison of visual signatures of query and DB frames. To produce visual signatures we also used two apporaches: the first one is the baseline Bag-Of-Visual-Words (BOVW) model based on SURF interest point descriptor; the second approach is a Bag-Of-Regions (BOR) model that extends the traditional notion of BOVW vocabulary not only to keypoint-based descriptors but to region based descriptors.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Delezoide2012] | <i class="icon-book"></i> <a href="/download/pdfs/Delezoide2012.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseErcolessi2012b_Conferenceandworkshopproceedings">
        Scene Clustering for TV Series Plot De-Interlacing based on Speakers, Dialogues and Images
        </a>
    </div>
    <div id="collapseErcolessi2012b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Christine Sénac, Sandrine Mouysset, Hervé Bredin
<p><em>AMVA 2012, 1st ACM International Workshop on Audio and Multimedia Methods for Large-Scale Video Analysis at ACM Multimedia 2012</em></p>
<blockquote><p>Recent TV series tend to have more and more complex plot. They follow the lives of numerous characters and are made of multiple intertwined stories. In this paper, we propose a hierarchical framework of plot de-interlacing  which permits to cluster semantic scenes into stories: a story is a group of scenes not necessarily contiguous but showing a strong semantic relation. Each scene is described using three different modalities (based on color histograms, speaker diarization or automatic speech recognition outputs) as well as their multimodal combination. We introduce the notion of character-driven episodes as episodes where stories are emphasized by the presence or absence of characters, and we propose an automatic method, based on a social graph, to detect these episodes. Depending on whether an episode is character-driven or not, the plot-de-interlacing -- which is a scene clustering -- is made either through a traditional average-link agglomerative clustering with speaker modality only, either through a  spectral clustering with the fusion of all modalities. Experiments, conducted on twenty three episodes from three quite different TV series (different lengths and formats), show that the hierarchical framework brings an improvement for all the series.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ercolessi2012b] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012b.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseErcolessi2012c_Conferenceandworkshopproceedings">
        StoViz: Story Visualization of TV Series
        </a>
    </div>
    <div id="collapseErcolessi2012c_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Hervé Bredin, Christine Sénac
<p><em>ACM MM 2012, 20th ACM International Conference on Multimedia</em></p>
<blockquote><p>Recent TV series tend to have more and more complex plot. They follow the lives of numerous characters and are made of multiple intertwined stories. In this paper, we introduce StoViz, a web-based interface allowing a fast overview of this kind of episode structure, based on our plot de-interlacing system. StoViz has two main goals. First, it provides the user with a useful overview of the episode by displaying each story separately and a short abstract extracted from them. Then, it allows an efficient visual comparison of the output of any automatic plot de-interlacing algorithm with the manual annotation in terms of stories and is therefore very helpful for evaluation purposes. StoViz is available online at http://stoviz.niderb.fr.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ercolessi2012c] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2012c.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2011</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseErcolessi2011_Conferenceandworkshopproceedings">
        Segmenting TV Series into Scenes using Speaker Diarization
        </a>
    </div>
    <div id="collapseErcolessi2011_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Philippe Ercolessi, Hervé Bredin, Christine Sénac, Philippe Joly
<p><em>WIAMIS 2011, 12th International Workshop on Image Analysis for Multimedia Interactive Services</em></p>
<blockquote><p>In this paper, we propose a novel approach to perform scene segmentation of TV series. Using the output of our existing speaker diarization system, any temporal segment of the video can be described as a binary feature vector. A straightforward segmentation algorithm then allows to group similar contiguous speaker segments into scenes. An additional visual-only color-based segmentation is then used to refine the first segmentation. Experiments are performed on a subset of the Ally McBeal TV series and show promising results, obtained with a rule-free and generic method. For comparison purposes, test corpus annotations and description are made available to the community.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Ercolessi2011] | <i class="icon-book"></i> <a href="/download/pdfs/Ercolessi2011.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseGorisse2011_Conferenceandworkshopproceedings">
        IRIM at TRECVID 2010: Semantic Indexing and Instance Search
        </a>
    </div>
    <div id="collapseGorisse2011_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        David Gorisse, Frédéric Precioso, Philippe Gosselin, Lionel Granjon, Denis Pellerin, Michèle Rombaut, Hervé Bredin, Lionel Koenig, Rémi Vieux, Boris Mansencal, Jenny Benois-Pineau, Hugo Boujut, Claire Morand, Hervé Jégou, Stéphane Ayache, Bahjat Safadi, Yubing Tong, Franck Thollard, Georges Quénot, Matthieu Cord, Alexandre Beno\^it, Patrick Lambert
<p><em>TRECVid 2010, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes our participation to the TRECVID 2010 semantic indexing and instance search tasks. For the semantic indexing task, we evaluated a number of different descriptors and tried different fusion strategies, in particular hierarchical fusion. The best IRIM run has a Mean Inferred Average Precision of 0.0442, which is above the task median performance. We found that fusion of the classification scores from different classifier types improves the performance and that even with a quite low individual performance, audio descriptors can help. For the instance search task, we used only one of the example images in our queries. The rank is nearly in the middle of the list of participants. The experiment showed that HSV features outperform the concatenation of HSV and Edge histograms or the Wavelet features.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Gorisse2011] | <i class="icon-book"></i> <a href="/download/pdfs/Gorisse2011.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2010</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2010_Conferenceandworkshopproceedings">
        IRIT at TRECVID HLF 2009: Audio to the Rescue
        </a>
    </div>
    <div id="collapseBredin2010_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Lionel Koenig, Hélène Lachambre, Elie El Khoury
<p><em>TRECVid 2009, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2010] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2010.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseDelezoide2010_Conferenceandworkshopproceedings">
        IRIM at TRECVID 2009: High Level Feature Extraction
        </a>
    </div>
    <div id="collapseDelezoide2010_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Delezoide, Bertrand, Le Borgne, Hervé, Moëllic, Pierre-Alain, Gorisse, David, Precioso, Frédéric, Wang, Feng, Merialdo, Bernard, Gosselin, Philippe, Granjon, Lionel, Pellerin, Denis, Rombaut, Michèle, Bredin, Hervé, Koenig, Lionel, Lachambre, Hélène, El Khoury, Elie, Mansencal, Boris, Zhou, Yifan, Benois-Pineau, Jenny, Jégou, Hervé, Ayache, Stéphane, Safadi, Bahjat, Quenot, Georges, Fabrizio, Jonathan, Cord, Matthieu, Glotin, Hervé, Zhao, Zhongqiu, Dumont, Emilie, Augereau, Bertrand
<p><em>TRECVid 2009, TREC Video Retrieval Evaluation Online Proceedings</em></p>
<blockquote><p>The IRIM group is a consortium of French teams working on Multimedia Indexing and Retrieval. This paper describes our participation to the TRECVID 2009 High Level Features detection task. We evaluated a large number of different descriptors (on TRECVID 2008 data) and tried different fusion strategies, in particular hierarchical fusion and genetic fusion. The best IRIM run has a Mean Inferred Average Precision of 0.1220, which is significantly above TRECVID 2009 HLF detection task median performance. We found that fusion of the classification scores from different classifier types improves the performance and that even with a quite low individual performance, audio descriptors can help.</p></blockquote>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Delezoide2010] | <i class="icon-book"></i> <a href="/download/pdfs/Delezoide2010.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2009</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseCooray2009_Conferenceandworkshopproceedings">
        An Interactive and Multi-Level Framework for Summarising User-Generated Videos
        </a>
    </div>
    <div id="collapseCooray2009_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Saman H. Cooray, Hervé Bredin, Li-Qun Xu, Noel E. O'Connor
<p><em>ACM MM 2009, 17th ACM International Conference on Multimedia</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Cooray2009] | <i class="icon-book"></i> <a href="/download/pdfs/Cooray2009.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2008</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseFauve2008_Conferenceandworkshopproceedings">
        Some Results from the BioSecure Talking-Face Evaluation Campaign
        </a>
    </div>
    <div id="collapseFauve2008_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Benoït Fauve, Hervé Bredin, Walid Karam, Florian Verdet, Aurélien Mayoue, Gérard Chollet, Jean Hennebert, R. Lewis, John Mason, Chafic Mokbel, Dijana Petrovska
<p><em>ICASSP 2008, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Fauve2008] | <i class="icon-book"></i> <a href="/download/pdfs/Fauve2008.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseDumont2008_Conferenceandworkshopproceedings">
        Rushes Video Summarization using a Collaborative Approach
        </a>
    </div>
    <div id="collapseDumont2008_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Emilie Dumont, Bernard Merialdo, Slim Essid, Werner Bailer, Herwig Rehatschek, Daragh Byrne, Hervé Bredin, Noel O'Connor, Gareth JF Jones, Alan F Smeaton, Martin Haller, Andreas Krutz, Thomas Sikora, Tomas Piatrik
<p><em>TRECVID 2008, ACM International Conference on Multimedia Information Retrieval</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Dumont2008] | <i class="icon-book"></i> <a href="/download/pdfs/Dumont2008.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2008_Conferenceandworkshopproceedings">
        Making Talking-Face Authentication Robust to Deliberate Imposture
        </a>
    </div>
    <div id="collapseBredin2008_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>ICASSP 2008, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2008] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2008.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2008a_Conferenceandworkshopproceedings">
        Dublin City University at TRECVid 2008 BBC Rushes Summarisation Task
        </a>
    </div>
    <div id="collapseBredin2008a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Daragh Byrne, Hyowon Lee, Noel O'Connor, Gareth JF Jones
<p><em>TRECVID 2008, ACM International Conference on Multimedia Information Retrieval 2008</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2008a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2008a.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseDumont2008a_Conferenceandworkshopproceedings">
        A Collaborative Approach to Video Summarization
        </a>
    </div>
    <div id="collapseDumont2008a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Emilie Dumont, Bernard Merialdo, Slim Essid, Werner Bailer, Daragh Byrne, Hervé Bredin, Noel O'Connor, Gareth JF Jones, Martin Haller, Andreas Krutz, Thomas Sikora, Tomas Piatrik
<p><em>SAMT 2008, 3rd International Conference on Semantic and Digital Media Technologies</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Dumont2008a] | <i class="icon-book"></i> <a href="/download/pdfs/Dumont2008a.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2007</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseLandais2007_Conferenceandworkshopproceedings">
        Vérification Audiovisuelle de l'Identité
        </a>
    </div>
    <div id="collapseLandais2007_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Rémi Landais, Hervé Bredin, Leila Zouari, Gérard Chollet
<p><em>Traitement et Analyse de l'Information : Méthodes et Applications</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Landais2007] | <i class="icon-book"></i> <a href="/download/pdfs/Landais2007.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapsePerrot2007_Conferenceandworkshopproceedings">
        Biometrics and Forensic Sciences: the Same Quest for Identification?
        </a>
    </div>
    <div id="collapsePerrot2007_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Patrick Perrot, Hervé Bredin, Gérard Chollet
<p><em>2007 International Crime Science Conference</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Perrot2007] | <i class="icon-book"></i> <a href="/download/pdfs/Perrot2007.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseArgones-Rua2007_Conferenceandworkshopproceedings">
        Aliveness Detection using Coupled Hidden Markov Models
        </a>
    </div>
    <div id="collapseArgones-Rua2007_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Enrique Argones-Rúa, Carmen García-Mateo, Hervé Bredin, Gérard Chollet
<p><em>1st Spanish Workshop on Biometrics</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Argones-Rua2007] | <i class="icon-book"></i> <a href="/download/pdfs/Argones-Rua2007.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2007a_Conferenceandworkshopproceedings">
        Audio-Visual Speech Synchrony Measure for Talking-Face Identity Verification
        </a>
    </div>
    <div id="collapseBredin2007a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>ICASSP 2007, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2007a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2007a.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2006</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2006a_Conferenceandworkshopproceedings">
        The BioSecure Talking-Face Reference System
        </a>
    </div>
    <div id="collapseBredin2006a_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Guido Aversano, Chafic Mokbel, Gérard Chollet
<p><em>MMUA 2006, Workshop on Multimodal User Authentication</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2006a] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006a.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBrugger2006_Conferenceandworkshopproceedings">
        Reconnaissance Audiovisuelle de la Parole par VMike
        </a>
    </div>
    <div id="collapseBrugger2006_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Fabian Brugger, Leila Zouari, Hervé Bredin, Asma Amehraye, Gérard Chollet, Dominique Pastor, Yang Ni
<p><em>JEP 2006, Journées d'Etudes sur la Parole</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Brugger2006] | <i class="icon-book"></i> <a href="/download/pdfs/Brugger2006.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseKoreman2006_Conferenceandworkshopproceedings">
        Multi-Modal Biometric Authentication on the SecurePhone PDA
        </a>
    </div>
    <div id="collapseKoreman2006_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Jacques Koreman, Andrew C Morris, D. Wu, Sabah Jassim, Harin Sellahewa, J. Ehlers, Gérard Chollet, Guido Aversano, Hervé Bredin, Sonia Garcia-Salicetti, Lorène Allano, Bao Ly Van, Bernadette Dorizzi
<p><em>MMUA 2006, Workshop on Multimodal User Authentication</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Koreman2006] | <i class="icon-book"></i> <a href="/download/pdfs/Koreman2006.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2006c_Conferenceandworkshopproceedings">
        Measuring Audio and Visual Speech Synchrony: Methods and Applications
        </a>
    </div>
    <div id="collapseBredin2006c_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Gérard Chollet
<p><em>VIE 2006, IEE International Conference on Visual Information Engineering</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2006c] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006c.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2006b_Conferenceandworkshopproceedings">
        GMM-based SVM for Face Recognition
        </a>
    </div>
    <div id="collapseBredin2006b_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Najim Dehak, Gérard Chollet
<p><em>ICPR 2006, IAPR International Conference on Pattern Recognition</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2006b] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006b.pdf">.pdf</a>        </div>
    </div>
</div>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseBredin2006_Conferenceandworkshopproceedings">
        Detecting Replay Attacks in Audiovisual Identity Verification
        </a>
    </div>
    <div id="collapseBredin2006_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Hervé Bredin, Antonio Miguel, Ian Witten, Gérard Chollet
<p><em>ICASSP 2006, IEEE International Conference on Acoustics, Speech, and Signal Processing</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [Bredin2006] | <i class="icon-book"></i> <a href="/download/pdfs/Bredin2006.pdf">.pdf</a>        </div>
    </div>
</div>
<h3>2005</h3>
<div class="accordion-group">
    <div class="accordion-heading">
        <a class="accordion-toggle" data-toggle="collapse" data-parent="#accordionConferenceandworkshopproceedings" href="#collapseMcTait2005_Conferenceandworkshopproceedings">
        Adapting a High Quality Audiovisual Database to PDA Quality
        </a>
    </div>
    <div id="collapseMcTait2005_Conferenceandworkshopproceedings" class="accordion-body collapse">
        <div class="accordion-inner">
        Kevin McTait, Hervé Bredin, Silvia Colón, Thomas Fillon, Gérard Chollet
<p><em>ISISPA 2005, International Symposium on Image and Signal Processing and Analysis</em></p>
<i class="icon-tags"></i> <a href="https://raw.github.com/hbredin/cv/master/publi/bredin.bib">.bib</a> [McTait2005] | <i class="icon-book"></i> <a href="/download/pdfs/McTait2005.pdf">.pdf</a>        </div>
    </div>
</div>
</div>
</div>
</div>
